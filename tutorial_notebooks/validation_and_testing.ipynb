{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "lLy5PsIql9A5"
   },
   "source": [
    "# 5. Validation & Testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "P6L-ynOvokKT"
   },
   "source": [
    "Welcome to the fifth notebook of our six part series part of our tutorial on Deep Learning for Human Activity Recognition. Within the last notebook you learned:\n",
    "\n",
    "- How do I define a sample neural network architecture in PyTorch? \n",
    "- What additional preprocessing do I need to apply to my data to fed it into my network?\n",
    "- How do I define a train loop which trains my neural network?\n",
    "\n",
    "This notebook will teach you everything you need to know about validation and testing. When building a predictive pipeline there are a lot of parameters which one needs to set before comencing the actual training. Coming up with a suitable set of hyperparameters is called hypertuning. In order to gain feedback whether the applied hyperparameters are a good choice, we check the predictive performance of our model on the validation set. This is called validation.\n",
    "\n",
    "Now you might ask yourself: Solely relying and tuning based on the validation scores would inherit that your trained model would end up being too well optimized on the validation set and thus not general anymore, right? If asked yourself that question, then you are 100% right in your assumption! This is what we call overfitting and is one of the major pitfalls in Machine Learning.Overfitting your model results in bad prediction performance on unseen data. \n",
    "\n",
    "We therefore need a third dataset, called the test dataset. The test dataset is a part of the initial dataset which you keep separate from all optimization steps. It is only used to gain insights on the predictive performance of the model and must not (!) be used as a reference for tuning hyperparameters. As we mentioned in during the theoretical parts of this tutorial, (supervised) Deep Learning, in our opinion, is just a fancy word for function approximation. If your model performs both well during validation and testing, it is a general function which properly approximates the underlying function.\n",
    "\n",
    "After completing this notebook you will be answer the following questions:\n",
    "- How do I split my initial dataset into a train, validation and test dataset?\n",
    "- What validation methods exist in Human Activity Recognition? How are they performed?\n",
    "- How is testing usually performed?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "G4fWjW5V0_MT"
   },
   "source": [
    "## 5.1. Important Remarks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "pkhCF6Pd1B1Z"
   },
   "source": [
    "If you are accessing this tutorial via [Google Colab](https://colab.research.google.com/github/mariusbock/dl-for-har/blob/main/tutorial_notebooks/training.ipynb), first make sure to use Google Colab in English. This will help us to better assist you with issues that might arise during the tutorial. There are two ways to change the default language if it isn't English already:\n",
    "1. On Google Colab, go to `Help` -> `View in English` \n",
    "2. Change the default language of your browser to `English`.\n",
    "\n",
    "To also ease the communication when communicating errors, enable line numbers within the settings of Colab.\n",
    "\n",
    "1. On Google Colab, go to `Tools` -> `Settings` -> `Editor` -> `Show line numbers`\n",
    "\n",
    "In general, we strongly advise you to use Google Colab as it provides you with a working Python distribution as well as free GPU resources. To make Colab use GPUs, you need to change the current notebooks runtime type via:\n",
    "\n",
    "- `Runtime` -> `Change runtime type` -> `Dropdown` -> `GPU` -> `Save`\n",
    "\n",
    "**Hint:** you can auto-complete code in Colab via `ctrl` + `spacebar`\n",
    "\n",
    "For the live tutorial, we require all participants to use Colab. If you decide to rerun the tutorial at later points and rather want to have it run locally on your machine, feel free to clone our [GitHub repository](https://github.com/mariusbock/dl-for-har).\n",
    "\n",
    "To get started with this notebook, you need to first run the code cell below. Please set `use_colab` to be `True` if you are accessing this notebook via Colab. If not, please set it to `False`. This code cell will make sure that imports from our GitHub repository will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "si3n5Sc51L-D"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "use_colab = False\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "if use_colab:\n",
    "    # move to content directory and remove directory for a clean start \n",
    "    %cd /content/         \n",
    "    %rm -rf dl-for-har\n",
    "    # clone package repository (will throw error if already cloned)\n",
    "    !git clone https://github.com/mariusbock/dl-for-har.git\n",
    "    # navigate to dl-for-har directory\n",
    "    %cd dl-for-har/       \n",
    "else:\n",
    "    os.chdir(module_path)\n",
    "    \n",
    "# this statement is needed so that we can use the methods of the DL-ARC pipeline\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "BIjrK-KE1iDL"
   },
   "source": [
    "## 5.1. Splitting your data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HrLU2e9H1oAX"
   },
   "source": [
    "Within the first part of this notebook we will split our data in the above mentioned three datasets, namely the train, validation and test dataset. There are multiple ways how to split the data into the two respective datasets, for example:\n",
    "\n",
    "- **Subject-wise:** split according to participants within the dataset. This means that we are reserving certain subjects to be included in the train, validation and test set respectively. For example, given that there are a total of 10 subjects, you could use 6 subjects for trainig, 2 subjects for validation and 2 subjects for testing.\n",
    "- **Percentage-wise:** state how large percentage-wise your train, validation and test dataset should be compared to the full dataset. For example, you could use 60% of your data for training, 20% for validation and 20% for testing. The three splits can also be chosen to be stratified, meaning that the relative label distribution within each of the two dataset is kept the same as in the full dataset. Note that stratifiying your data would require the data to be shuffled.\n",
    "- **Record-wise:** state how many records should be in your train, validation and test dataset should be contained, i.e. define two cutoff points. For example, given that there are 1 million records in your full dataset, you could have the first 600 thousand records to be contained in the train dataset, the next 200 thousand in the validation dataset and the remaining 200 thousand records to be contained in the test dataset.\n",
    "\n",
    "**WARNING:** shuffling your dataset during splitting (which is e.g. needed for stratified splits) will destroy the time-dependencies among the data records. To minimize this effect, apply a sliding window on top of your data before splitting. This way, time-dependencies will at least be preserved within the windows. While working on this notebook, we will notify you when this is necessary.\n",
    "\n",
    "To keep things simple and fast, we will be splitting our data subject-wise. We will use the first data of the first subject for training, the data of the second subject for validation and the data of the third subject for testing. Your first task will be to perform said split. Note that we already imported the dataset for you using the `load_dataset()` function, which is part of the DL-ARC feature stack."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "MIAoSI0Ql9BC"
   },
   "source": [
    "### Task 1: Split the data into train, validation and test data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "1_QkR_bHl9BC"
   },
   "source": [
    "1. Define the `train` dataset to be the data of the first subject, i.e. with `subject_identifier = 0`. (`lines 13-14`)\n",
    "2. Define the `valid` dataset to be the data of the second subject, i.e. with `subject_identifier = 1`. (`lines 15-16`)\n",
    "3. Define the `test` dataset to be the data of the third subject, i.e. with `subject_identifier = 2`. (`lines 17-18`)\n",
    "4. Define a fourth dataset being a concatenated version of the `train` and `valid` dataset called `train_valid`. You will need this dataset for some of the validation methods. Use `np.concatenate()` in order to concat the two numpy arrays along `axis=0`. (`lines 20-21`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "el2x8KMJl9BE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset files ...\n",
      "Full dataset with size: | X (659260, 4) | y (659260,) | \n",
      " ..from file data/rwhar_3sbjs_data.csv\n",
      "\n",
      "Shape of the train, validation and test dataset:\n",
      "(78004, 5) (87572, 5) (14261, 5)\n",
      "\n",
      "Shape of the concatenated train_valid dataset:\n",
      "(165576, 5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from data_processing.preprocess_data import load_dataset\n",
    "\n",
    "\n",
    "# data loading (we are using a predefined method called load_dataset, which is part of the DL-ARC feature stack)\n",
    "X, y, num_classes, class_names, sampling_rate, has_null = load_dataset('rwhar_3sbjs', include_null=True)\n",
    "# since the method returns features and labels separatley, we need to concat them\n",
    "data = np.concatenate((X, y[:, None]), axis=1)\n",
    "\n",
    "# define the train data to be the data of the first subject\n",
    "train_data = data[data[:, -1]==0]\n",
    "# define the valid data to be the data of the second subject\n",
    "valid_data = data[data[:, -1]==1]\n",
    "# define the test data to be the data of the third subject\n",
    "test_data = data[data[:, -1]==2]\n",
    "\n",
    "# define the train_valid_data by concatenating the train and validation dataset \n",
    "train_valid_data = np.concatenate((train_data, valid_data), 0)\n",
    "\n",
    "print('\\nShape of the train, validation and test dataset:')\n",
    "print(train_data.shape, valid_data.shape, test_data.shape)\n",
    "print('\\nShape of the concatenated train_valid dataset:')\n",
    "print(train_valid_data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HzCPsMcd4koA"
   },
   "source": [
    "## 5.2. Define the hyperparameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "u_q8TpPal9BE"
   },
   "source": [
    "Before we go over talking about how to perform validation in Human Activtiy Recognition, we need to define our hyperparameters again. As you know from the previous notebook, it is common practice to track all your settings and parameters in a compiled `config` object. Due to fact that we will be using pre-implemented methods of the feature stack of the DL-ARC GitHub, we will now need to define a more complex `config` object. \n",
    "\n",
    "Within the next code block we defined a sample `config` object for you. It contains some parameters which you already know from previous notebooks, but also lots which you don't know. We will not cover all of them during this tutorial, but encourage you to check out the complete implementation of the DL-ARC. We also separated the parameters into two groups for you, once which you can play around with and ones which you should handle with care and rather leave as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jjZYXFX6l9BF"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    #### TRY AND CHANGE THESE PARAMETERS ####\n",
    "    # sliding window settings\n",
    "    'sw_length': 50,\n",
    "    'sw_unit': 'units',\n",
    "    'sampling_rate': 50,\n",
    "    'sw_overlap': 30,\n",
    "    # network settings\n",
    "    'nb_conv_blocks': 2,\n",
    "    'conv_block_type': 'normal',\n",
    "    'nb_filters': 64,\n",
    "    'filter_width': 11,\n",
    "    'nb_units_lstm': 128,\n",
    "    'nb_layers_lstm': 1,\n",
    "    'drop_prob': 0.5,\n",
    "    # training settings\n",
    "    'epochs': 10,\n",
    "    'batch_size': 100,\n",
    "    'loss': 'cross_entropy',\n",
    "    'use_weights': True,\n",
    "    'weights_init': 'xavier_uniform',\n",
    "    'optimizer': 'adam',\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 1e-6,\n",
    "    ### UP FROM HERE YOU SHOULD RATHER NOT CHANGE THESE ####\n",
    "    'batch_norm': False,\n",
    "    'dilation': 1,\n",
    "    'pooling': False,\n",
    "    'pool_type': 'max',\n",
    "    'pool_kernel_width': 2,\n",
    "    'reduce_layer': False,\n",
    "    'reduce_layer_output': 10,\n",
    "    'nb_classes': 8,\n",
    "    'seed': 1,\n",
    "    'gpu': 'cuda:0',\n",
    "    'verbose': False,\n",
    "    'print_freq': 10,\n",
    "    'save_gradient_plot': False,\n",
    "    'print_counts': False,\n",
    "    'adj_lr': False,\n",
    "    'adj_lr_patience': 5,\n",
    "    'early_stopping': False,\n",
    "    'es_patience': 5,\n",
    "    'save_test_preds': False,\n",
    "    'no_lstm': False,\n",
    "    'weighted': False,\n",
    "    'shuffling': True,\n",
    "    'smoothing' : True,\n",
    "    'valid_epoch' : 'no_best'\n",
    "\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "T0WRQj1dl9BF"
   },
   "source": [
    "## 5.3. Validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "GhwdRETQ8t9D"
   },
   "source": [
    "Within the next segment we will explain the most prominent validation methods used in Human Activity Recognition. These are:\n",
    "\n",
    "- Train-Valid Split\n",
    "- k-Fold Cross-Validation\n",
    "- Cross-Participant Cross-Validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "kQPUaRRE8AC9"
   },
   "source": [
    "### 5.3.1. Train-Valid Split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "r8BS4Qf3l9BF"
   },
   "source": [
    "The train-valid split is one of the most basic validation method, which you  already did yourself. Instead of varying the validation set and getting a more holistic view, we define it to be a set part of the data. As mentioned above there are multiple ways how to do so. For simplicity purposes, we chose to use a subject-wise split. Within the next task you will be asked to train your network using the `train` data and obtain predictions on the `valid` data. We do not ask you to define the training loop again and allow you to use the built-in `train` function of the DL-ARC."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "dOcMYLvTl9BF"
   },
   "source": [
    "#### Task 2: Implementing the train-valid split validation loop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XsRp7hDNl9BF"
   },
   "source": [
    "1. As you already defined the train and valid dataset you can go ahead and apply a sliding window on top of both datasets. You can use the predefined method `apply_sliding_window()`, which is part of the DL-ARC pipeline, to do so. It is already be imported for you. We will give you hints on what to pass the method. (`lines 22-30`)\n",
    "2. (*Optional*) Omit the first feature column (subject_identifier) from the train and validation dataset. (`lines 32-34`)\n",
    "3. Within the `config` object, set the parameters `window_size` and `nb_channels` accordingly. (`lines 36-40`)\n",
    "4. Define the `DeepConvLSTM` object. It is already imported for you. Also define the `optimizer` being the [Adam optimizer](https://pytorch.org/docs/stable/optim.html) and `criterion` being the [Cross-Entropy Loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) (`lines 42-48`)\n",
    "5. Convert the feature columns of the train and validation to `float32` and label column to `uint8` for GPU compatibility. Use the [built-in function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html) of a pandas dataframe called `astype()`. (`lines 50-52`)\n",
    "6. Use both datasets to run the `train()` function. (`lines 54-55`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "61uZSoSdl9BG",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78004, 5) (87572, 5)\n",
      "(2226, 50, 4) (2226,)\n",
      "(2499, 50, 4) (2499,)\n",
      "+----------------------------+------------+\n",
      "|          Modules           | Parameters |\n",
      "+----------------------------+------------+\n",
      "| conv_blocks.0.conv1.weight |    704     |\n",
      "|  conv_blocks.0.conv1.bias  |     64     |\n",
      "| conv_blocks.0.conv2.weight |   45056    |\n",
      "|  conv_blocks.0.conv2.bias  |     64     |\n",
      "| conv_blocks.1.conv1.weight |   45056    |\n",
      "|  conv_blocks.1.conv1.bias  |     64     |\n",
      "| conv_blocks.1.conv2.weight |   45056    |\n",
      "|  conv_blocks.1.conv2.bias  |     64     |\n",
      "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
      "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
      "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
      "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
      "|         fc.weight          |    1024    |\n",
      "|          fc.bias           |     8      |\n",
      "+----------------------------+------------+\n",
      "Total Params: 302024\n",
      "EPOCH: 1/10 \n",
      "Train Loss: 1.3483 Train Acc (M): 0.0920 Train Prc (M): 0.1250 Train Rcl (M): 0.0920 Train F1 (M): 0.1060 Train Acc (W): 0.7363 Train Prc (W): 1.0000 Train Rcl (W): 0.7363 Train F1 (W): 0.8481 \n",
      "Valid Loss: 3.4228 Valid Acc (M): 0.0000 Valid Prc (M): 0.0000 Valid Rcl (M): 0.0000 Valid F1 (M): 0.0000 Valid Acc (W): 0.0000 Valid Prc (W): 0.0000 Valid Rcl (W): 0.0000 Valid F1 (W): 0.0000\n",
      "EPOCH: 2/10 \n",
      "Train Loss: 0.0979 Train Acc (M): 0.1250 Train Prc (M): 0.1250 Train Rcl (M): 0.1250 Train F1 (M): 0.1250 Train Acc (W): 1.0000 Train Prc (W): 1.0000 Train Rcl (W): 1.0000 Train F1 (W): 1.0000 \n",
      "Valid Loss: 6.2503 Valid Acc (M): 0.0000 Valid Prc (M): 0.0000 Valid Rcl (M): 0.0000 Valid F1 (M): 0.0000 Valid Acc (W): 0.0000 Valid Prc (W): 0.0000 Valid Rcl (W): 0.0000 Valid F1 (W): 0.0000\n",
      "EPOCH: 3/10 \n",
      "Train Loss: 0.0129 Train Acc (M): 0.1250 Train Prc (M): 0.1250 Train Rcl (M): 0.1250 Train F1 (M): 0.1250 Train Acc (W): 1.0000 Train Prc (W): 1.0000 Train Rcl (W): 1.0000 Train F1 (W): 1.0000 \n",
      "Valid Loss: 7.6857 Valid Acc (M): 0.0000 Valid Prc (M): 0.0000 Valid Rcl (M): 0.0000 Valid F1 (M): 0.0000 Valid Acc (W): 0.0000 Valid Prc (W): 0.0000 Valid Rcl (W): 0.0000 Valid F1 (W): 0.0000\n",
      "EPOCH: 4/10 \n",
      "Train Loss: 0.0059 Train Acc (M): 0.1250 Train Prc (M): 0.1250 Train Rcl (M): 0.1250 Train F1 (M): 0.1250 Train Acc (W): 1.0000 Train Prc (W): 1.0000 Train Rcl (W): 1.0000 Train F1 (W): 1.0000 \n",
      "Valid Loss: 8.4112 Valid Acc (M): 0.0000 Valid Prc (M): 0.0000 Valid Rcl (M): 0.0000 Valid F1 (M): 0.0000 Valid Acc (W): 0.0000 Valid Prc (W): 0.0000 Valid Rcl (W): 0.0000 Valid F1 (W): 0.0000\n",
      "EPOCH: 5/10 \n",
      "Train Loss: 0.0037 Train Acc (M): 0.1250 Train Prc (M): 0.1250 Train Rcl (M): 0.1250 Train F1 (M): 0.1250 Train Acc (W): 1.0000 Train Prc (W): 1.0000 Train Rcl (W): 1.0000 Train F1 (W): 1.0000 \n",
      "Valid Loss: 8.9318 Valid Acc (M): 0.0000 Valid Prc (M): 0.0000 Valid Rcl (M): 0.0000 Valid F1 (M): 0.0000 Valid Acc (W): 0.0000 Valid Prc (W): 0.0000 Valid Rcl (W): 0.0000 Valid F1 (W): 0.0000\n",
      "EPOCH: 6/10 \n",
      "Train Loss: 0.0023 Train Acc (M): 0.1250 Train Prc (M): 0.1250 Train Rcl (M): 0.1250 Train F1 (M): 0.1250 Train Acc (W): 1.0000 Train Prc (W): 1.0000 Train Rcl (W): 1.0000 Train F1 (W): 1.0000 \n",
      "Valid Loss: 9.2944 Valid Acc (M): 0.0000 Valid Prc (M): 0.0000 Valid Rcl (M): 0.0000 Valid F1 (M): 0.0000 Valid Acc (W): 0.0000 Valid Prc (W): 0.0000 Valid Rcl (W): 0.0000 Valid F1 (W): 0.0000\n",
      "EPOCH: 7/10 \n",
      "Train Loss: 0.0017 Train Acc (M): 0.1250 Train Prc (M): 0.1250 Train Rcl (M): 0.1250 Train F1 (M): 0.1250 Train Acc (W): 1.0000 Train Prc (W): 1.0000 Train Rcl (W): 1.0000 Train F1 (W): 1.0000 \n",
      "Valid Loss: 9.5628 Valid Acc (M): 0.0000 Valid Prc (M): 0.0000 Valid Rcl (M): 0.0000 Valid F1 (M): 0.0000 Valid Acc (W): 0.0000 Valid Prc (W): 0.0000 Valid Rcl (W): 0.0000 Valid F1 (W): 0.0000\n",
      "EPOCH: 8/10 \n",
      "Train Loss: 0.0015 Train Acc (M): 0.1250 Train Prc (M): 0.1250 Train Rcl (M): 0.1250 Train F1 (M): 0.1250 Train Acc (W): 1.0000 Train Prc (W): 1.0000 Train Rcl (W): 1.0000 Train F1 (W): 1.0000 \n",
      "Valid Loss: 9.8075 Valid Acc (M): 0.0000 Valid Prc (M): 0.0000 Valid Rcl (M): 0.0000 Valid F1 (M): 0.0000 Valid Acc (W): 0.0000 Valid Prc (W): 0.0000 Valid Rcl (W): 0.0000 Valid F1 (W): 0.0000\n",
      "EPOCH: 9/10 \n",
      "Train Loss: 0.0011 Train Acc (M): 0.1250 Train Prc (M): 0.1250 Train Rcl (M): 0.1250 Train F1 (M): 0.1250 Train Acc (W): 1.0000 Train Prc (W): 1.0000 Train Rcl (W): 1.0000 Train F1 (W): 1.0000 \n",
      "Valid Loss: 9.9999 Valid Acc (M): 0.0000 Valid Prc (M): 0.0000 Valid Rcl (M): 0.0000 Valid F1 (M): 0.0000 Valid Acc (W): 0.0000 Valid Prc (W): 0.0000 Valid Rcl (W): 0.0000 Valid F1 (W): 0.0000\n",
      "EPOCH: 10/10 \n",
      "Train Loss: 0.0009 Train Acc (M): 0.1250 Train Prc (M): 0.1250 Train Rcl (M): 0.1250 Train F1 (M): 0.1250 Train Acc (W): 1.0000 Train Prc (W): 1.0000 Train Rcl (W): 1.0000 Train F1 (W): 1.0000 \n",
      "Valid Loss: 10.1274 Valid Acc (M): 0.0000 Valid Prc (M): 0.0000 Valid Rcl (M): 0.0000 Valid F1 (M): 0.0000 Valid Acc (W): 0.0000 Valid Prc (W): 0.0000 Valid Rcl (W): 0.0000 Valid F1 (W): 0.0000\n",
      "\n",
      "VALIDATION RESULTS: \n",
      "\n",
      "Avg. Accuracy: 0.0\n",
      "Avg. Precision: 0.0\n",
      "Avg. Recall: 0.0\n",
      "Avg. F1: 0.0\n",
      "\n",
      "VALIDATION RESULTS (PER CLASS): \n",
      "\n",
      "Accuracy:\n",
      "   climbing_down: 0.0\n",
      "   climbing_up: 0.0\n",
      "   jumping: 0.0\n",
      "   lying: 0.0\n",
      "   running: 0.0\n",
      "   sitting: 0.0\n",
      "   standing: 0.0\n",
      "   walking: 0.0\n",
      "\n",
      "Precision:\n",
      "   climbing_down: 0.0\n",
      "   climbing_up: 0.0\n",
      "   jumping: 0.0\n",
      "   lying: 0.0\n",
      "   running: 0.0\n",
      "   sitting: 0.0\n",
      "   standing: 0.0\n",
      "   walking: 0.0\n",
      "\n",
      "Recall:\n",
      "   climbing_down: 0.0\n",
      "   climbing_up: 0.0\n",
      "   jumping: 0.0\n",
      "   lying: 0.0\n",
      "   running: 0.0\n",
      "   sitting: 0.0\n",
      "   standing: 0.0\n",
      "   walking: 0.0\n",
      "\n",
      "F1:\n",
      "   climbing_down: 0.0\n",
      "   climbing_up: 0.0\n",
      "   jumping: 0.0\n",
      "   lying: 0.0\n",
      "   running: 0.0\n",
      "   sitting: 0.0\n",
      "   standing: 0.0\n",
      "   walking: 0.0\n",
      "\n",
      "GENERALIZATION GAP ANALYSIS: \n",
      "\n",
      "Train-Val-Accuracy Difference: 1.0\n",
      "Train-Val-Precision Difference: 1.0\n",
      "Train-Val-Recall Difference: 1.0\n",
      "Train-Val-F1 Difference: 1.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score\n",
    "from model.train import train\n",
    "from model.DeepConvLSTM import DeepConvLSTM\n",
    "from data_processing.sliding_window import apply_sliding_window\n",
    "from misc.torchutils import seed_torch\n",
    "\n",
    "\n",
    "# in order to get reproducible results, we need to seed torch and other random parts of our implementation\n",
    "seed_torch(config['seed'])\n",
    "\n",
    "# needed for saving results\n",
    "log_date = time.strftime('%Y%m%d')\n",
    "log_timestamp = time.strftime('%H%M%S')\n",
    "\n",
    "print(train_data.shape, valid_data.shape)\n",
    "\n",
    "# apply the sliding window on top of both the train and validation data; use the \"apply_sliding_window\" function\n",
    "# found in data_processing.sliding_window\n",
    "X_train, y_train = apply_sliding_window(train_data[:, :-1], train_data[:,-1], sliding_window_size= config['sw_length'], unit=config['sw_unit'], sampling_rate=config['sampling_rate'], sliding_window_overlap=config['sw_overlap'])\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "X_valid, y_valid = apply_sliding_window(valid_data[:, :-1], valid_data[:,-1], sliding_window_size= config['sw_length'], unit=config['sw_unit'], sampling_rate=config['sampling_rate'], sliding_window_overlap=config['sw_overlap'])\n",
    "\n",
    "print(X_valid.shape, y_valid.shape)\n",
    "\n",
    "# (optional) omit the first feature column (subject_identifier) from the train and validation dataset\n",
    "# you can do it if you want to as it is not a useful feature\n",
    "X_train, X_valid = X_train[:, :, 1:], X_valid[:, :, 1:]\n",
    "\n",
    "# within the config file, set the parameters 'window_size' and 'nb_channels' accordingly\n",
    "# window_size = size of the sliding window in units\n",
    "# nb_channels = number of feature channels\n",
    "config['window_size'] = X_train.shape[1]\n",
    "config['nb_channels'] = X_train.shape[2]\n",
    "\n",
    "# define the network to be a DeepConvLSTM object; can be imported from model.DeepConvLSTM\n",
    "# pass it the config object\n",
    "net = DeepConvLSTM(config=config)\n",
    "\n",
    "# defines the loss and optimizer\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(params=net.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "\n",
    "# convert the features of the train and validation to float32 and labels to uint8 for GPU compatibility \n",
    "X_train, y_train = X_train.astype(np.float32), y_train.astype(np.uint8)\n",
    "X_valid, y_valid = X_valid.astype(np.float32), y_valid.astype(np.uint8)\n",
    "\n",
    "# feed the datasets into the train function; can be imported from model.train\n",
    "train_valid_net,_, val_output, train_output = train(X_train, y_train, X_valid, y_valid, net, opt, loss, config, log_date, log_timestamp)\n",
    "\n",
    "# the next bit prints out your results if you did everything correctly\n",
    "cls = np.array(range(config['nb_classes']))\n",
    "\n",
    "print('\\nVALIDATION RESULTS: ')\n",
    "print(\"\\nAvg. Accuracy: {0}\".format(jaccard_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
    "print(\"Avg. Precision: {0}\".format(precision_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
    "print(\"Avg. Recall: {0}\".format(recall_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
    "print(\"Avg. F1: {0}\".format(f1_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
    "\n",
    "print(\"\\nVALIDATION RESULTS (PER CLASS): \")\n",
    "print(\"\\nAccuracy:\")\n",
    "for i, rslt in enumerate(jaccard_score(val_output[:, 1], val_output[:, 0], average=None, labels=cls)):\n",
    "    print(\"   {0}: {1}\".format(class_names[i], rslt))\n",
    "print(\"\\nPrecision:\")\n",
    "for i, rslt in enumerate(precision_score(val_output[:, 1], val_output[:, 0], average=None, labels=cls)):\n",
    "    print(\"   {0}: {1}\".format(class_names[i], rslt))\n",
    "print(\"\\nRecall:\")\n",
    "for i, rslt in enumerate(recall_score(val_output[:, 1], val_output[:, 0], average=None, labels=cls)):\n",
    "    print(\"   {0}: {1}\".format(class_names[i], rslt))\n",
    "print(\"\\nF1:\")\n",
    "for i, rslt in enumerate(f1_score(val_output[:, 1], val_output[:, 0], average=None, labels=cls)):\n",
    "    print(\"   {0}: {1}\".format(class_names[i], rslt))\n",
    "\n",
    "print(\"\\nGENERALIZATION GAP ANALYSIS: \")\n",
    "print(\"\\nTrain-Val-Accuracy Difference: {0}\".format(jaccard_score(train_output[:, 1], train_output[:, 0], average='macro') -\n",
    "                                                  jaccard_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
    "print(\"Train-Val-Precision Difference: {0}\".format(precision_score(train_output[:, 1], train_output[:, 0], average='macro') -\n",
    "                                                   precision_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
    "print(\"Train-Val-Recall Difference: {0}\".format(recall_score(train_output[:, 1], train_output[:, 0], average='macro') -\n",
    "                                                recall_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
    "print(\"Train-Val-F1 Difference: {0}\".format(f1_score(train_output[:, 1], train_output[:, 0], average='macro') -\n",
    "                                            f1_score(val_output[:, 1], val_output[:, 0], average='macro')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_BepnQk8l9BH"
   },
   "source": [
    "### 5.3.2. K-Fold Cross-Validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "5OlOGi55l9BJ"
   },
   "source": [
    "The k-fold cross-validation is the most popular form of cross-validation. Instead of only splitting our data once into a train and validation dataset, like we did in the previous validation method, we take the average of k different train-valid splits. To do so we take our concatenated version of the train and validation set and split it into k equal-sized chunks of data. A so-called fold is now that we train our network using all but one of these chunks of data and validate it using the chunk we excluded (thus being unseen data). The process is repeated k-times, i.e. k-folds, so that each chunk of data is the validation dataset exactly once. Note that with each fold, the network needs to be reinitialized, i.e. trained from scratch, to ensure that it is not predicting already seen data.\n",
    "\n",
    "\n",
    "**Note:** It is recommended to use stratified k-fold cross-validation, i.e. each of the k chunks of data has the same distribution of labels as the original full dataset. This avoids the risk, especially for unbalanced datasets, of having certain labels missing within the train dataset, which would cause the validation process to break. Nevertheless, as also stated above, stratification requires shuffling and thus one should always first apply the sliding window before applying the split.\n",
    "\n",
    "The next task will lead you through the implementation of the k-fold cross-validation loop. In order to chunk your data and also apply stratification, we recommend you to use the scikit-learn helper object for stratified k-fold cross-validation called `StratifiedKFold`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "1sK2SCNYl9BJ"
   },
   "source": [
    "#### Task 3: Implementing the k-fold CV loop "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "iirq5yFll9BK"
   },
   "source": [
    "1. Define the scikit-learn helper object for stratified k-fold cross-validation called `StratifiedKFold`. It is already imported for you. We will also give you hints what to pass it as arguments. (`lines 14-16`)\n",
    "2. Apply the `apply_sliding_window()` function on top of the `train_valid_data` object which you previously defined. (`lines 20-24`)\n",
    "3. (*Optional*) Omit the first feature column (subject_identifier) from the `train_valid_data` dataset. (`lines 26-28`)\n",
    "4. Define the k-fold loop; use the `split()` function of the `StratifiedKFold` object to obtain indeces to split the `train_valid_data` (`lines 42-49`)\n",
    "5. Within the `config` object, set the parameters `window_size` and `nb_channels` accordingly. (`lines 51-55`)\n",
    "6. Define the `DeepConvLSTM` object. It is already imported for you. Also define the `optimizer` being the [Adam optimizer](https://pytorch.org/docs/stable/optim.html) and `criterion` being the [Cross-Entropy Loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) (`lines 57-63`)\n",
    "7. Convert the feature columns of the train and validation to `float32` and label column to `uint8` for GPU compatibility. Use the [built-in function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html) of a pandas dataframe called `astype()`. (`lines 65-67`)\n",
    "8. Use both datasets to run the `train()` function. (`lines 69-70`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Wnh-tBGAl9BK",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165576, 5)\n",
      "(4728, 50, 4) (4728,)\n",
      "\n",
      "Fold 1/10\n",
      "+----------------------------+------------+\n",
      "|          Modules           | Parameters |\n",
      "+----------------------------+------------+\n",
      "| conv_blocks.0.conv1.weight |    704     |\n",
      "|  conv_blocks.0.conv1.bias  |     64     |\n",
      "| conv_blocks.0.conv2.weight |   45056    |\n",
      "|  conv_blocks.0.conv2.bias  |     64     |\n",
      "| conv_blocks.1.conv1.weight |   45056    |\n",
      "|  conv_blocks.1.conv1.bias  |     64     |\n",
      "| conv_blocks.1.conv2.weight |   45056    |\n",
      "|  conv_blocks.1.conv2.bias  |     64     |\n",
      "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
      "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
      "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
      "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
      "|         fc.weight          |    1024    |\n",
      "|          fc.bias           |     8      |\n",
      "+----------------------------+------------+\n",
      "Total Params: 302024\n",
      "EPOCH: 1/10 \n",
      "Train Loss: 1.2804 Train Acc (M): 0.0760 Train Prc (M): 0.1240 Train Rcl (M): 0.1114 Train F1 (M): 0.1151 Train Acc (W): 0.3088 Train Prc (W): 0.4975 Train Rcl (W): 0.4541 Train F1 (W): 0.4660 \n",
      "Valid Loss: 0.7302 Valid Acc (M): 0.0765 Valid Prc (M): 0.1269 Valid Rcl (M): 0.1259 Valid F1 (M): 0.1093 Valid Acc (W): 0.3166 Valid Prc (W): 0.5088 Valid Rcl (W): 0.5243 Valid F1 (W): 0.4499\n",
      "Performance improved... (0.0->0.43730073546128917)\n",
      "EPOCH: 2/10 \n",
      "Train Loss: 0.7872 Train Acc (M): 0.0835 Train Prc (M): 0.1250 Train Rcl (M): 0.1250 Train F1 (M): 0.1248 Train Acc (W): 0.3367 Train Prc (W): 0.5019 Train Rcl (W): 0.5041 Train F1 (W): 0.5022 \n",
      "Valid Loss: 0.6907 Valid Acc (M): 0.1059 Valid Prc (M): 0.1549 Valid Rcl (M): 0.1499 Valid F1 (M): 0.1471 Valid Acc (W): 0.4290 Valid Prc (W): 0.6184 Valid Rcl (W): 0.6110 Valid F1 (W): 0.5938\n",
      "Performance improved... (0.43730073546128917->0.5883221070158177)\n",
      "EPOCH: 3/10 \n",
      "Train Loss: 0.7529 Train Acc (M): 0.0871 Train Prc (M): 0.1291 Train Rcl (M): 0.1290 Train F1 (M): 0.1290 Train Acc (W): 0.3508 Train Prc (W): 0.5179 Train Rcl (W): 0.5194 Train F1 (W): 0.5182 \n",
      "Valid Loss: 0.6685 Valid Acc (M): 0.1084 Valid Prc (M): 0.1599 Valid Rcl (M): 0.1528 Valid F1 (M): 0.1493 Valid Acc (W): 0.4396 Valid Prc (W): 0.6375 Valid Rcl (W): 0.6237 Valid F1 (W): 0.6032\n",
      "Performance improved... (0.5883221070158177->0.5973274410774411)\n",
      "EPOCH: 4/10 \n",
      "Train Loss: 0.7126 Train Acc (M): 0.0963 Train Prc (M): 0.1391 Train Rcl (M): 0.1388 Train F1 (M): 0.1386 Train Acc (W): 0.3879 Train Prc (W): 0.5578 Train Rcl (W): 0.5598 Train F1 (W): 0.5574 \n",
      "Valid Loss: 0.6420 Valid Acc (M): 0.1352 Valid Prc (M): 0.1759 Valid Rcl (M): 0.1753 Valid F1 (M): 0.1754 Valid Acc (W): 0.5428 Valid Prc (W): 0.7038 Valid Rcl (W): 0.7040 Valid F1 (W): 0.7031\n",
      "Performance improved... (0.5973274410774411->0.7015503875968991)\n",
      "EPOCH: 5/10 \n",
      "Train Loss: 0.6585 Train Acc (M): 0.1136 Train Prc (M): 0.1563 Train Rcl (M): 0.1560 Train F1 (M): 0.1560 Train Acc (W): 0.4564 Train Prc (W): 0.6261 Train Rcl (W): 0.6270 Train F1 (W): 0.6259 \n",
      "Valid Loss: 0.5797 Valid Acc (M): 0.1442 Valid Prc (M): 0.1836 Valid Rcl (M): 0.1835 Valid F1 (M): 0.1829 Valid Acc (W): 0.5766 Valid Prc (W): 0.7369 Valid Rcl (W): 0.7315 Valid F1 (W): 0.7314\n",
      "Performance improved... (0.7015503875968991->0.7314962565649792)\n",
      "EPOCH: 6/10 \n",
      "Train Loss: 0.6051 Train Acc (M): 0.1281 Train Prc (M): 0.1699 Train Rcl (M): 0.1692 Train F1 (M): 0.1692 Train Acc (W): 0.5147 Train Prc (W): 0.6798 Train Rcl (W): 0.6801 Train F1 (W): 0.6788 \n",
      "Valid Loss: 0.5472 Valid Acc (M): 0.1420 Valid Prc (M): 0.1888 Valid Rcl (M): 0.1811 Valid F1 (M): 0.1805 Valid Acc (W): 0.5720 Valid Prc (W): 0.7519 Valid Rcl (W): 0.7336 Valid F1 (W): 0.7252\n",
      "EPOCH: 7/10 \n",
      "Train Loss: 0.5629 Train Acc (M): 0.1417 Train Prc (M): 0.1812 Train Rcl (M): 0.1806 Train F1 (M): 0.1808 Train Acc (W): 0.5686 Train Prc (W): 0.7251 Train Rcl (W): 0.7253 Train F1 (W): 0.7245 \n",
      "Valid Loss: 0.5199 Valid Acc (M): 0.1520 Valid Prc (M): 0.1957 Valid Rcl (M): 0.1887 Valid F1 (M): 0.1886 Valid Acc (W): 0.6114 Valid Prc (W): 0.7794 Valid Rcl (W): 0.7632 Valid F1 (W): 0.7572\n",
      "Performance improved... (0.7314962565649792->0.7545225385527876)\n",
      "EPOCH: 8/10 \n",
      "Train Loss: 0.5434 Train Acc (M): 0.1453 Train Prc (M): 0.1844 Train Rcl (M): 0.1835 Train F1 (M): 0.1837 Train Acc (W): 0.5832 Train Prc (W): 0.7375 Train Rcl (W): 0.7373 Train F1 (W): 0.7362 \n",
      "Valid Loss: 0.5106 Valid Acc (M): 0.1548 Valid Prc (M): 0.1952 Valid Rcl (M): 0.1908 Valid F1 (M): 0.1909 Valid Acc (W): 0.6220 Valid Prc (W): 0.7782 Valid Rcl (W): 0.7696 Valid F1 (W): 0.7659\n",
      "Performance improved... (0.7545225385527876->0.763774152016238)\n",
      "EPOCH: 9/10 \n",
      "Train Loss: 0.5184 Train Acc (M): 0.1517 Train Prc (M): 0.1892 Train Rcl (M): 0.1885 Train F1 (M): 0.1887 Train Acc (W): 0.6083 Train Prc (W): 0.7568 Train Rcl (W): 0.7568 Train F1 (W): 0.7561 \n",
      "Valid Loss: 0.4791 Valid Acc (M): 0.1593 Valid Prc (M): 0.1953 Valid Rcl (M): 0.1943 Valid F1 (M): 0.1945 Valid Acc (W): 0.6389 Valid Prc (W): 0.7808 Valid Rcl (W): 0.7801 Valid F1 (W): 0.7793\n",
      "Performance improved... (0.763774152016238->0.7781185725110958)\n",
      "EPOCH: 10/10 \n",
      "Train Loss: 0.5102 Train Acc (M): 0.1564 Train Prc (M): 0.1927 Train Rcl (M): 0.1921 Train F1 (M): 0.1923 Train Acc (W): 0.6269 Train Prc (W): 0.7709 Train Rcl (W): 0.7709 Train F1 (W): 0.7704 \n",
      "Valid Loss: 0.4893 Valid Acc (M): 0.1520 Valid Prc (M): 0.1890 Valid Rcl (M): 0.1890 Valid F1 (M): 0.1890 Valid Acc (W): 0.6090 Valid Prc (W): 0.7568 Valid Rcl (W): 0.7569 Valid F1 (W): 0.7568\n",
      "\n",
      "Fold 2/10\n",
      "+----------------------------+------------+\n",
      "|          Modules           | Parameters |\n",
      "+----------------------------+------------+\n",
      "| conv_blocks.0.conv1.weight |    704     |\n",
      "|  conv_blocks.0.conv1.bias  |     64     |\n",
      "| conv_blocks.0.conv2.weight |   45056    |\n",
      "|  conv_blocks.0.conv2.bias  |     64     |\n",
      "| conv_blocks.1.conv1.weight |   45056    |\n",
      "|  conv_blocks.1.conv1.bias  |     64     |\n",
      "| conv_blocks.1.conv2.weight |   45056    |\n",
      "|  conv_blocks.1.conv2.bias  |     64     |\n",
      "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
      "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
      "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
      "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
      "|         fc.weight          |    1024    |\n",
      "|          fc.bias           |     8      |\n",
      "+----------------------------+------------+\n",
      "Total Params: 302024\n",
      "EPOCH: 1/10 \n",
      "Train Loss: 1.2310 Train Acc (M): 0.0779 Train Prc (M): 0.1228 Train Rcl (M): 0.1159 Train F1 (M): 0.1187 Train Acc (W): 0.3113 Train Prc (W): 0.4928 Train Rcl (W): 0.4616 Train F1 (W): 0.4748 \n",
      "Valid Loss: 0.7441 Valid Acc (M): 0.0786 Valid Prc (M): 0.1278 Valid Rcl (M): 0.1272 Valid F1 (M): 0.1175 Valid Acc (W): 0.3090 Valid Prc (W): 0.5133 Valid Rcl (W): 0.4947 Valid F1 (W): 0.4635\n",
      "Performance improved... (0.0->0.4700714871674675)\n",
      "EPOCH: 2/10 \n",
      "Train Loss: 0.7870 Train Acc (M): 0.0844 Train Prc (M): 0.1260 Train Rcl (M): 0.1260 Train F1 (M): 0.1257 Train Acc (W): 0.3404 Train Prc (W): 0.5058 Train Rcl (W): 0.5088 Train F1 (W): 0.5059 \n",
      "Valid Loss: 0.7098 Valid Acc (M): 0.1029 Valid Prc (M): 0.1463 Valid Rcl (M): 0.1457 Valid F1 (M): 0.1454 Valid Acc (W): 0.4146 Valid Prc (W): 0.5861 Valid Rcl (W): 0.5877 Valid F1 (W): 0.5844\n",
      "Performance improved... (0.4700714871674675->0.5814444217548159)\n",
      "EPOCH: 3/10 \n",
      "Train Loss: 0.7504 Train Acc (M): 0.0894 Train Prc (M): 0.1316 Train Rcl (M): 0.1315 Train F1 (M): 0.1314 Train Acc (W): 0.3598 Train Prc (W): 0.5278 Train Rcl (W): 0.5293 Train F1 (W): 0.5281 \n",
      "Valid Loss: 0.6910 Valid Acc (M): 0.1070 Valid Prc (M): 0.1508 Valid Rcl (M): 0.1497 Valid F1 (M): 0.1493 Valid Acc (W): 0.4311 Valid Prc (W): 0.6036 Valid Rcl (W): 0.6047 Valid F1 (W): 0.6004\n",
      "Performance improved... (0.5814444217548159->0.5972781867934236)\n",
      "EPOCH: 4/10 \n",
      "Train Loss: 0.7171 Train Acc (M): 0.0962 Train Prc (M): 0.1389 Train Rcl (M): 0.1387 Train F1 (M): 0.1386 Train Acc (W): 0.3872 Train Prc (W): 0.5570 Train Rcl (W): 0.5586 Train F1 (W): 0.5570 \n",
      "Valid Loss: 0.6641 Valid Acc (M): 0.1215 Valid Prc (M): 0.1684 Valid Rcl (M): 0.1637 Valid F1 (M): 0.1627 Valid Acc (W): 0.4902 Valid Prc (W): 0.6718 Valid Rcl (W): 0.6638 Valid F1 (W): 0.6545\n",
      "Performance improved... (0.5972781867934236->0.6506306180753954)\n",
      "EPOCH: 5/10 \n",
      "Train Loss: 0.6681 Train Acc (M): 0.1094 Train Prc (M): 0.1523 Train Rcl (M): 0.1520 Train F1 (M): 0.1520 Train Acc (W): 0.4397 Train Prc (W): 0.6100 Train Rcl (W): 0.6110 Train F1 (W): 0.6099 \n",
      "Valid Loss: 0.6246 Valid Acc (M): 0.1272 Valid Prc (M): 0.1687 Valid Rcl (M): 0.1688 Valid F1 (M): 0.1686 Valid Acc (W): 0.5091 Valid Prc (W): 0.6765 Valid Rcl (W): 0.6744 Valid F1 (W): 0.6747\n",
      "Performance improved... (0.6506306180753954->0.6742424242424243)\n",
      "EPOCH: 6/10 \n",
      "Train Loss: 0.6087 Train Acc (M): 0.1273 Train Prc (M): 0.1692 Train Rcl (M): 0.1684 Train F1 (M): 0.1685 Train Acc (W): 0.5113 Train Prc (W): 0.6771 Train Rcl (W): 0.6773 Train F1 (W): 0.6758 \n",
      "Valid Loss: 0.5654 Valid Acc (M): 0.1429 Valid Prc (M): 0.1824 Valid Rcl (M): 0.1824 Valid F1 (M): 0.1818 Valid Acc (W): 0.5714 Valid Prc (W): 0.7320 Valid Rcl (W): 0.7273 Valid F1 (W): 0.7273\n",
      "Performance improved... (0.6742424242424243->0.7272727272727273)\n",
      "EPOCH: 7/10 \n",
      "Train Loss: 0.5592 Train Acc (M): 0.1404 Train Prc (M): 0.1805 Train Rcl (M): 0.1795 Train F1 (M): 0.1796 Train Acc (W): 0.5636 Train Prc (W): 0.7218 Train Rcl (W): 0.7215 Train F1 (W): 0.7202 \n",
      "Valid Loss: 0.5180 Valid Acc (M): 0.1480 Valid Prc (M): 0.1919 Valid Rcl (M): 0.1856 Valid F1 (M): 0.1854 Valid Acc (W): 0.5953 Valid Prc (W): 0.7644 Valid Rcl (W): 0.7505 Valid F1 (W): 0.7445\n",
      "Performance improved... (0.7272727272727273->0.7417931162102147)\n",
      "EPOCH: 8/10 \n",
      "Train Loss: 0.5405 Train Acc (M): 0.1461 Train Prc (M): 0.1852 Train Rcl (M): 0.1841 Train F1 (M): 0.1842 Train Acc (W): 0.5862 Train Prc (W): 0.7405 Train Rcl (W): 0.7398 Train F1 (W): 0.7386 \n",
      "Valid Loss: 0.5024 Valid Acc (M): 0.1568 Valid Prc (M): 0.1927 Valid Rcl (M): 0.1927 Valid F1 (M): 0.1927 Valid Acc (W): 0.6284 Valid Prc (W): 0.7716 Valid Rcl (W): 0.7717 Valid F1 (W): 0.7716\n",
      "Performance improved... (0.7417931162102147->0.7708086572628405)\n",
      "EPOCH: 9/10 \n",
      "Train Loss: 0.5065 Train Acc (M): 0.1540 Train Prc (M): 0.1913 Train Rcl (M): 0.1903 Train F1 (M): 0.1905 Train Acc (W): 0.6178 Train Prc (W): 0.7649 Train Rcl (W): 0.7643 Train F1 (W): 0.7633 \n",
      "Valid Loss: 0.4772 Valid Acc (M): 0.1577 Valid Prc (M): 0.1946 Valid Rcl (M): 0.1931 Valid F1 (M): 0.1933 Valid Acc (W): 0.6328 Valid Prc (W): 0.7775 Valid Rcl (W): 0.7759 Valid F1 (W): 0.7747\n",
      "Performance improved... (0.7708086572628405->0.7732625447704498)\n",
      "EPOCH: 10/10 \n",
      "Train Loss: 0.4743 Train Acc (M): 0.1595 Train Prc (M): 0.1953 Train Rcl (M): 0.1944 Train F1 (M): 0.1947 Train Acc (W): 0.6395 Train Prc (W): 0.7809 Train Rcl (W): 0.7805 Train F1 (W): 0.7798 \n",
      "Valid Loss: 0.5094 Valid Acc (M): 0.1481 Valid Prc (M): 0.1879 Valid Rcl (M): 0.1871 Valid F1 (M): 0.1860 Valid Acc (W): 0.5917 Valid Prc (W): 0.7551 Valid Rcl (W): 0.7442 Valid F1 (W): 0.7434\n",
      "\n",
      "Fold 3/10\n",
      "+----------------------------+------------+\n",
      "|          Modules           | Parameters |\n",
      "+----------------------------+------------+\n",
      "| conv_blocks.0.conv1.weight |    704     |\n",
      "|  conv_blocks.0.conv1.bias  |     64     |\n",
      "| conv_blocks.0.conv2.weight |   45056    |\n",
      "|  conv_blocks.0.conv2.bias  |     64     |\n",
      "| conv_blocks.1.conv1.weight |   45056    |\n",
      "|  conv_blocks.1.conv1.bias  |     64     |\n",
      "| conv_blocks.1.conv2.weight |   45056    |\n",
      "|  conv_blocks.1.conv2.bias  |     64     |\n",
      "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
      "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
      "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
      "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
      "|         fc.weight          |    1024    |\n",
      "|          fc.bias           |     8      |\n",
      "+----------------------------+------------+\n",
      "Total Params: 302024\n",
      "EPOCH: 1/10 \n",
      "Train Loss: 1.1667 Train Acc (M): 0.0825 Train Prc (M): 0.1294 Train Rcl (M): 0.1229 Train F1 (M): 0.1215 Train Acc (W): 0.3363 Train Prc (W): 0.5189 Train Rcl (W): 0.5036 Train F1 (W): 0.4934 \n",
      "Valid Loss: 0.7420 Valid Acc (M): 0.0826 Valid Prc (M): 0.1247 Valid Rcl (M): 0.1247 Valid F1 (M): 0.1228 Valid Acc (W): 0.3350 Valid Prc (W): 0.5004 Valid Rcl (W): 0.5074 Valid F1 (W): 0.4965\n",
      "Performance improved... (0.0->0.49135794492161)\n",
      "EPOCH: 2/10 \n",
      "Train Loss: 0.7821 Train Acc (M): 0.0872 Train Prc (M): 0.1292 Train Rcl (M): 0.1291 Train F1 (M): 0.1289 Train Acc (W): 0.3517 Train Prc (W): 0.5185 Train Rcl (W): 0.5210 Train F1 (W): 0.5186 \n",
      "Valid Loss: 0.6932 Valid Acc (M): 0.1008 Valid Prc (M): 0.1713 Valid Rcl (M): 0.1495 Valid F1 (M): 0.1390 Valid Acc (W): 0.4124 Valid Prc (W): 0.6795 Valid Rcl (W): 0.6173 Valid F1 (W): 0.5653\n",
      "Performance improved... (0.49135794492161->0.5558408948239457)\n",
      "EPOCH: 3/10 \n",
      "Train Loss: 0.7431 Train Acc (M): 0.0881 Train Prc (M): 0.1302 Train Rcl (M): 0.1301 Train F1 (M): 0.1298 Train Acc (W): 0.3550 Train Prc (W): 0.5222 Train Rcl (W): 0.5246 Train F1 (W): 0.5223 \n",
      "Valid Loss: 0.6954 Valid Acc (M): 0.0873 Valid Prc (M): 0.1394 Valid Rcl (M): 0.1342 Valid F1 (M): 0.1249 Valid Acc (W): 0.3577 Valid Prc (W): 0.5573 Valid Rcl (W): 0.5539 Valid F1 (W): 0.5089\n",
      "EPOCH: 4/10 \n",
      "Train Loss: 0.7229 Train Acc (M): 0.0920 Train Prc (M): 0.1348 Train Rcl (M): 0.1344 Train F1 (M): 0.1339 Train Acc (W): 0.3713 Train Prc (W): 0.5403 Train Rcl (W): 0.5434 Train F1 (W): 0.5390 \n",
      "Valid Loss: 0.6754 Valid Acc (M): 0.1077 Valid Prc (M): 0.1507 Valid Rcl (M): 0.1503 Valid F1 (M): 0.1503 Valid Acc (W): 0.4330 Valid Prc (W): 0.6036 Valid Rcl (W): 0.6047 Valid F1 (W): 0.6033\n",
      "Performance improved... (0.5558408948239457->0.6012002182214948)\n",
      "EPOCH: 5/10 \n",
      "Train Loss: 0.6936 Train Acc (M): 0.1031 Train Prc (M): 0.1459 Train Rcl (M): 0.1457 Train F1 (M): 0.1457 Train Acc (W): 0.4143 Train Prc (W): 0.5849 Train Rcl (W): 0.5859 Train F1 (W): 0.5850 \n",
      "Valid Loss: 0.6249 Valid Acc (M): 0.1248 Valid Prc (M): 0.1666 Valid Rcl (M): 0.1667 Valid F1 (M): 0.1664 Valid Acc (W): 0.4996 Valid Prc (W): 0.6680 Valid Rcl (W): 0.6660 Valid F1 (W): 0.6662\n",
      "Performance improved... (0.6012002182214948->0.6657811885084612)\n",
      "EPOCH: 6/10 \n",
      "Train Loss: 0.6268 Train Acc (M): 0.1260 Train Prc (M): 0.1684 Train Rcl (M): 0.1673 Train F1 (M): 0.1673 Train Acc (W): 0.5065 Train Prc (W): 0.6737 Train Rcl (W): 0.6736 Train F1 (W): 0.6713 \n",
      "Valid Loss: 0.5745 Valid Acc (M): 0.1303 Valid Prc (M): 0.1761 Valid Rcl (M): 0.1736 Valid F1 (M): 0.1712 Valid Acc (W): 0.5195 Valid Prc (W): 0.7089 Valid Rcl (W): 0.6871 Valid F1 (W): 0.6832\n",
      "Performance improved... (0.6657811885084612->0.684734832108373)\n",
      "EPOCH: 7/10 \n",
      "Train Loss: 0.5920 Train Acc (M): 0.1355 Train Prc (M): 0.1760 Train Rcl (M): 0.1755 Train F1 (M): 0.1757 Train Acc (W): 0.5439 Train Prc (W): 0.7045 Train Rcl (W): 0.7048 Train F1 (W): 0.7041 \n",
      "Valid Loss: 0.5099 Valid Acc (M): 0.1545 Valid Prc (M): 0.1914 Valid Rcl (M): 0.1907 Valid F1 (M): 0.1909 Valid Acc (W): 0.6196 Valid Prc (W): 0.7654 Valid Rcl (W): 0.7653 Valid F1 (W): 0.7648\n",
      "Performance improved... (0.684734832108373->0.763637345866591)\n",
      "EPOCH: 8/10 \n",
      "Train Loss: 0.5503 Train Acc (M): 0.1450 Train Prc (M): 0.1842 Train Rcl (M): 0.1832 Train F1 (M): 0.1834 Train Acc (W): 0.5820 Train Prc (W): 0.7367 Train Rcl (W): 0.7363 Train F1 (W): 0.7352 \n",
      "Valid Loss: 0.4761 Valid Acc (M): 0.1582 Valid Prc (M): 0.1938 Valid Rcl (M): 0.1937 Valid F1 (M): 0.1937 Valid Acc (W): 0.6339 Valid Prc (W): 0.7758 Valid Rcl (W): 0.7759 Valid F1 (W): 0.7758\n",
      "Performance improved... (0.763637345866591->0.7749317675788263)\n",
      "EPOCH: 9/10 \n",
      "Train Loss: 0.5017 Train Acc (M): 0.1546 Train Prc (M): 0.1918 Train Rcl (M): 0.1908 Train F1 (M): 0.1910 Train Acc (W): 0.6203 Train Prc (W): 0.7668 Train Rcl (W): 0.7662 Train F1 (W): 0.7652 \n",
      "Valid Loss: 0.4330 Valid Acc (M): 0.1693 Valid Prc (M): 0.2068 Valid Rcl (M): 0.2013 Valid F1 (M): 0.2017 Valid Acc (W): 0.6799 Valid Prc (W): 0.8238 Valid Rcl (W): 0.8118 Valid F1 (W): 0.8086\n",
      "Performance improved... (0.7749317675788263->0.8068528535968764)\n",
      "EPOCH: 10/10 \n",
      "Train Loss: 0.4887 Train Acc (M): 0.1587 Train Prc (M): 0.1946 Train Rcl (M): 0.1939 Train F1 (M): 0.1940 Train Acc (W): 0.6362 Train Prc (W): 0.7781 Train Rcl (W): 0.7779 Train F1 (W): 0.7773 \n",
      "Valid Loss: 0.4258 Valid Acc (M): 0.1654 Valid Prc (M): 0.1991 Valid Rcl (M): 0.1990 Valid F1 (M): 0.1991 Valid Acc (W): 0.6627 Valid Prc (W): 0.7970 Valid Rcl (W): 0.7970 Valid F1 (W): 0.7970\n",
      "\n",
      "Fold 4/10\n",
      "+----------------------------+------------+\n",
      "|          Modules           | Parameters |\n",
      "+----------------------------+------------+\n",
      "| conv_blocks.0.conv1.weight |    704     |\n",
      "|  conv_blocks.0.conv1.bias  |     64     |\n",
      "| conv_blocks.0.conv2.weight |   45056    |\n",
      "|  conv_blocks.0.conv2.bias  |     64     |\n",
      "| conv_blocks.1.conv1.weight |   45056    |\n",
      "|  conv_blocks.1.conv1.bias  |     64     |\n",
      "| conv_blocks.1.conv2.weight |   45056    |\n",
      "|  conv_blocks.1.conv2.bias  |     64     |\n",
      "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
      "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
      "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
      "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
      "|         fc.weight          |    1024    |\n",
      "|          fc.bias           |     8      |\n",
      "+----------------------------+------------+\n",
      "Total Params: 302024\n",
      "EPOCH: 1/10 \n",
      "Train Loss: 1.3221 Train Acc (M): 0.0770 Train Prc (M): 0.1285 Train Rcl (M): 0.1091 Train F1 (M): 0.1170 Train Acc (W): 0.3113 Train Prc (W): 0.5154 Train Rcl (W): 0.4418 Train F1 (W): 0.4720 \n",
      "Valid Loss: 0.7345 Valid Acc (M): 0.0940 Valid Prc (M): 0.1375 Valid Rcl (M): 0.1368 Valid F1 (M): 0.1358 Valid Acc (W): 0.3799 Valid Prc (W): 0.5508 Valid Rcl (W): 0.5539 Valid F1 (W): 0.5473\n",
      "Performance improved... (0.0->0.5433297490219406)\n",
      "EPOCH: 2/10 \n",
      "Train Loss: 0.8050 Train Acc (M): 0.0875 Train Prc (M): 0.1295 Train Rcl (M): 0.1294 Train F1 (M): 0.1293 Train Acc (W): 0.3524 Train Prc (W): 0.5196 Train Rcl (W): 0.5213 Train F1 (W): 0.5199 \n",
      "Valid Loss: 0.6753 Valid Acc (M): 0.1222 Valid Prc (M): 0.1659 Valid Rcl (M): 0.1639 Valid F1 (M): 0.1637 Valid Acc (W): 0.4918 Valid Prc (W): 0.6632 Valid Rcl (W): 0.6617 Valid F1 (W): 0.6576\n",
      "Performance improved... (0.5433297490219406->0.6548075168764824)\n",
      "EPOCH: 3/10 \n",
      "Train Loss: 0.7606 Train Acc (M): 0.0934 Train Prc (M): 0.1359 Train Rcl (M): 0.1358 Train F1 (M): 0.1357 Train Acc (W): 0.3758 Train Prc (W): 0.5450 Train Rcl (W): 0.5464 Train F1 (W): 0.5452 \n",
      "Valid Loss: 0.6385 Valid Acc (M): 0.1309 Valid Prc (M): 0.1722 Valid Rcl (M): 0.1715 Valid F1 (M): 0.1716 Valid Acc (W): 0.5253 Valid Prc (W): 0.6889 Valid Rcl (W): 0.6892 Valid F1 (W): 0.6882\n",
      "Performance improved... (0.6548075168764824->0.6865049843773248)\n",
      "EPOCH: 4/10 \n",
      "Train Loss: 0.7074 Train Acc (M): 0.1031 Train Prc (M): 0.1459 Train Rcl (M): 0.1458 Train F1 (M): 0.1458 Train Acc (W): 0.4143 Train Prc (W): 0.5850 Train Rcl (W): 0.5857 Train F1 (W): 0.5852 \n",
      "Valid Loss: 0.5992 Valid Acc (M): 0.1481 Valid Prc (M): 0.1877 Valid Rcl (M): 0.1871 Valid F1 (M): 0.1860 Valid Acc (W): 0.5918 Valid Prc (W): 0.7542 Valid Rcl (W): 0.7442 Valid F1 (W): 0.7435\n",
      "Performance improved... (0.6865049843773248->0.7439617416667785)\n",
      "EPOCH: 5/10 \n",
      "Train Loss: 0.6391 Train Acc (M): 0.1226 Train Prc (M): 0.1645 Train Rcl (M): 0.1644 Train F1 (M): 0.1644 Train Acc (W): 0.4919 Train Prc (W): 0.6589 Train Rcl (W): 0.6592 Train F1 (W): 0.6590 \n",
      "Valid Loss: 0.5326 Valid Acc (M): 0.1449 Valid Prc (M): 0.1841 Valid Rcl (M): 0.1831 Valid F1 (M): 0.1833 Valid Acc (W): 0.5813 Valid Prc (W): 0.7360 Valid Rcl (W): 0.7357 Valid F1 (W): 0.7347\n",
      "EPOCH: 6/10 \n",
      "Train Loss: 0.5852 Train Acc (M): 0.1364 Train Prc (M): 0.1768 Train Rcl (M): 0.1762 Train F1 (M): 0.1763 Train Acc (W): 0.5473 Train Prc (W): 0.7073 Train Rcl (W): 0.7076 Train F1 (W): 0.7069 \n",
      "Valid Loss: 0.5162 Valid Acc (M): 0.1529 Valid Prc (M): 0.1910 Valid Rcl (M): 0.1906 Valid F1 (M): 0.1897 Valid Acc (W): 0.6112 Valid Prc (W): 0.7672 Valid Rcl (W): 0.7590 Valid F1 (W): 0.7586\n",
      "Performance improved... (0.7439617416667785->0.7588979110030047)\n",
      "EPOCH: 7/10 \n",
      "Train Loss: 0.5431 Train Acc (M): 0.1484 Train Prc (M): 0.1865 Train Rcl (M): 0.1860 Train F1 (M): 0.1862 Train Acc (W): 0.5952 Train Prc (W): 0.7463 Train Rcl (W): 0.7464 Train F1 (W): 0.7459 \n",
      "Valid Loss: 0.5131 Valid Acc (M): 0.1420 Valid Prc (M): 0.1981 Valid Rcl (M): 0.1818 Valid F1 (M): 0.1800 Valid Acc (W): 0.5732 Valid Prc (W): 0.7863 Valid Rcl (W): 0.7400 Valid F1 (W): 0.7244\n",
      "EPOCH: 8/10 \n",
      "Train Loss: 0.5086 Train Acc (M): 0.1516 Train Prc (M): 0.1895 Train Rcl (M): 0.1884 Train F1 (M): 0.1886 Train Acc (W): 0.6083 Train Prc (W): 0.7576 Train Rcl (W): 0.7570 Train F1 (W): 0.7559 \n",
      "Valid Loss: 0.4729 Valid Acc (M): 0.1649 Valid Prc (M): 0.1989 Valid Rcl (M): 0.1991 Valid F1 (M): 0.1987 Valid Acc (W): 0.6599 Valid Prc (W): 0.7978 Valid Rcl (W): 0.7949 Valid F1 (W): 0.7951\n",
      "Performance improved... (0.7588979110030047->0.794867323899582)\n",
      "EPOCH: 9/10 \n",
      "Train Loss: 0.4802 Train Acc (M): 0.1608 Train Prc (M): 0.1962 Train Rcl (M): 0.1954 Train F1 (M): 0.1956 Train Acc (W): 0.6447 Train Prc (W): 0.7846 Train Rcl (W): 0.7843 Train F1 (W): 0.7836 \n",
      "Valid Loss: 0.4739 Valid Acc (M): 0.1599 Valid Prc (M): 0.1954 Valid Rcl (M): 0.1955 Valid F1 (M): 0.1950 Valid Acc (W): 0.6397 Valid Prc (W): 0.7837 Valid Rcl (W): 0.7801 Valid F1 (W): 0.7802\n",
      "EPOCH: 10/10 \n",
      "Train Loss: 0.4735 Train Acc (M): 0.1626 Train Prc (M): 0.1976 Train Rcl (M): 0.1968 Train F1 (M): 0.1970 Train Acc (W): 0.6521 Train Prc (W): 0.7900 Train Rcl (W): 0.7897 Train F1 (W): 0.7891 \n",
      "Valid Loss: 0.4220 Valid Acc (M): 0.1666 Valid Prc (M): 0.2036 Valid Rcl (M): 0.1994 Valid F1 (M): 0.1997 Valid Acc (W): 0.6686 Valid Prc (W): 0.8119 Valid Rcl (W): 0.8034 Valid F1 (W): 0.8007\n",
      "Performance improved... (0.794867323899582->0.7989800254993625)\n",
      "\n",
      "Fold 5/10\n",
      "+----------------------------+------------+\n",
      "|          Modules           | Parameters |\n",
      "+----------------------------+------------+\n",
      "| conv_blocks.0.conv1.weight |    704     |\n",
      "|  conv_blocks.0.conv1.bias  |     64     |\n",
      "| conv_blocks.0.conv2.weight |   45056    |\n",
      "|  conv_blocks.0.conv2.bias  |     64     |\n",
      "| conv_blocks.1.conv1.weight |   45056    |\n",
      "|  conv_blocks.1.conv1.bias  |     64     |\n",
      "| conv_blocks.1.conv2.weight |   45056    |\n",
      "|  conv_blocks.1.conv2.bias  |     64     |\n",
      "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
      "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
      "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
      "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
      "|         fc.weight          |    1024    |\n",
      "|          fc.bias           |     8      |\n",
      "+----------------------------+------------+\n",
      "Total Params: 302024\n",
      "EPOCH: 1/10 \n",
      "Train Loss: 1.3241 Train Acc (M): 0.0758 Train Prc (M): 0.1241 Train Rcl (M): 0.1140 Train F1 (M): 0.1132 Train Acc (W): 0.3101 Train Prc (W): 0.4983 Train Rcl (W): 0.4691 Train F1 (W): 0.4609 \n",
      "Valid Loss: 0.7308 Valid Acc (M): 0.0933 Valid Prc (M): 0.1364 Valid Rcl (M): 0.1359 Valid F1 (M): 0.1352 Valid Acc (W): 0.3766 Valid Prc (W): 0.5466 Valid Rcl (W): 0.5497 Valid F1 (W): 0.5444\n",
      "Performance improved... (0.0->0.5407411121696836)\n",
      "EPOCH: 2/10 \n",
      "Train Loss: 0.7809 Train Acc (M): 0.0875 Train Prc (M): 0.1295 Train Rcl (M): 0.1294 Train F1 (M): 0.1292 Train Acc (W): 0.3524 Train Prc (W): 0.5194 Train Rcl (W): 0.5215 Train F1 (W): 0.5196 \n",
      "Valid Loss: 0.6797 Valid Acc (M): 0.0989 Valid Prc (M): 0.1577 Valid Rcl (M): 0.1459 Valid F1 (M): 0.1379 Valid Acc (W): 0.4036 Valid Prc (W): 0.6278 Valid Rcl (W): 0.6004 Valid F1 (W): 0.5601\n",
      "Performance improved... (0.5407411121696836->0.5516542707116098)\n",
      "EPOCH: 3/10 \n",
      "Train Loss: 0.7477 Train Acc (M): 0.0890 Train Prc (M): 0.1311 Train Rcl (M): 0.1310 Train F1 (M): 0.1309 Train Acc (W): 0.3583 Train Prc (W): 0.5260 Train Rcl (W): 0.5278 Train F1 (W): 0.5262 \n",
      "Valid Loss: 0.6620 Valid Acc (M): 0.1213 Valid Prc (M): 0.1645 Valid Rcl (M): 0.1631 Valid F1 (M): 0.1629 Valid Acc (W): 0.4878 Valid Prc (W): 0.6580 Valid Rcl (W): 0.6575 Valid F1 (W): 0.6543\n",
      "Performance improved... (0.5516542707116098->0.6517126649940002)\n",
      "EPOCH: 4/10 \n",
      "Train Loss: 0.7172 Train Acc (M): 0.0954 Train Prc (M): 0.1382 Train Rcl (M): 0.1379 Train F1 (M): 0.1378 Train Acc (W): 0.3844 Train Prc (W): 0.5541 Train Rcl (W): 0.5561 Train F1 (W): 0.5538 \n",
      "Valid Loss: 0.6345 Valid Acc (M): 0.1288 Valid Prc (M): 0.1721 Valid Rcl (M): 0.1697 Valid F1 (M): 0.1696 Valid Acc (W): 0.5181 Valid Prc (W): 0.6876 Valid Rcl (W): 0.6850 Valid F1 (W): 0.6810\n",
      "Performance improved... (0.6517126649940002->0.6783414344720567)\n",
      "EPOCH: 5/10 \n",
      "Train Loss: 0.6749 Train Acc (M): 0.1096 Train Prc (M): 0.1524 Train Rcl (M): 0.1522 Train F1 (M): 0.1522 Train Acc (W): 0.4402 Train Prc (W): 0.6105 Train Rcl (W): 0.6113 Train F1 (W): 0.6106 \n",
      "Valid Loss: 0.5765 Valid Acc (M): 0.1454 Valid Prc (M): 0.1840 Valid Rcl (M): 0.1842 Valid F1 (M): 0.1839 Valid Acc (W): 0.5823 Valid Prc (W): 0.7376 Valid Rcl (W): 0.7357 Valid F1 (W): 0.7359\n",
      "Performance improved... (0.6783414344720567->0.7355591833083615)\n",
      "EPOCH: 6/10 \n",
      "Train Loss: 0.6213 Train Acc (M): 0.1276 Train Prc (M): 0.1694 Train Rcl (M): 0.1687 Train F1 (M): 0.1688 Train Acc (W): 0.5126 Train Prc (W): 0.6779 Train Rcl (W): 0.6783 Train F1 (W): 0.6770 \n",
      "Valid Loss: 0.5178 Valid Acc (M): 0.1515 Valid Prc (M): 0.1894 Valid Rcl (M): 0.1893 Valid F1 (M): 0.1887 Valid Acc (W): 0.6061 Valid Prc (W): 0.7600 Valid Rcl (W): 0.7548 Valid F1 (W): 0.7547\n",
      "Performance improved... (0.7355591833083615->0.7547557748694844)\n",
      "EPOCH: 7/10 \n",
      "Train Loss: 0.5829 Train Acc (M): 0.1364 Train Prc (M): 0.1766 Train Rcl (M): 0.1763 Train F1 (M): 0.1764 Train Acc (W): 0.5472 Train Prc (W): 0.7070 Train Rcl (W): 0.7074 Train F1 (W): 0.7069 \n",
      "Valid Loss: 0.4893 Valid Acc (M): 0.1556 Valid Prc (M): 0.1917 Valid Rcl (M): 0.1919 Valid F1 (M): 0.1918 Valid Acc (W): 0.6229 Valid Prc (W): 0.7682 Valid Rcl (W): 0.7674 Valid F1 (W): 0.7676\n",
      "Performance improved... (0.7547557748694844->0.767066007664482)\n",
      "EPOCH: 8/10 \n",
      "Train Loss: 0.5455 Train Acc (M): 0.1454 Train Prc (M): 0.1845 Train Rcl (M): 0.1835 Train F1 (M): 0.1837 Train Acc (W): 0.5834 Train Prc (W): 0.7379 Train Rcl (W): 0.7375 Train F1 (W): 0.7363 \n",
      "Valid Loss: 0.4584 Valid Acc (M): 0.1597 Valid Prc (M): 0.1949 Valid Rcl (M): 0.1949 Valid F1 (M): 0.1949 Valid Acc (W): 0.6397 Valid Prc (W): 0.7801 Valid Rcl (W): 0.7801 Valid F1 (W): 0.7801\n",
      "Performance improved... (0.767066007664482->0.7794080717488789)\n",
      "EPOCH: 9/10 \n",
      "Train Loss: 0.5294 Train Acc (M): 0.1497 Train Prc (M): 0.1877 Train Rcl (M): 0.1870 Train F1 (M): 0.1872 Train Acc (W): 0.6005 Train Prc (W): 0.7507 Train Rcl (W): 0.7506 Train F1 (W): 0.7500 \n",
      "Valid Loss: 0.4529 Valid Acc (M): 0.1623 Valid Prc (M): 0.1998 Valid Rcl (M): 0.1963 Valid F1 (M): 0.1966 Valid Acc (W): 0.6515 Valid Prc (W): 0.7969 Valid Rcl (W): 0.7907 Valid F1 (W): 0.7882\n",
      "Performance improved... (0.7794080717488789->0.7865416436845007)\n",
      "EPOCH: 10/10 \n",
      "Train Loss: 0.4850 Train Acc (M): 0.1596 Train Prc (M): 0.1953 Train Rcl (M): 0.1945 Train F1 (M): 0.1947 Train Acc (W): 0.6399 Train Prc (W): 0.7810 Train Rcl (W): 0.7807 Train F1 (W): 0.7801 \n",
      "Valid Loss: 0.4181 Valid Acc (M): 0.1718 Valid Prc (M): 0.2044 Valid Rcl (M): 0.2034 Valid F1 (M): 0.2036 Valid Acc (W): 0.6888 Valid Prc (W): 0.8170 Valid Rcl (W): 0.8161 Valid F1 (W): 0.8154\n",
      "Performance improved... (0.7865416436845007->0.8144621336110698)\n",
      "\n",
      "Fold 6/10\n",
      "+----------------------------+------------+\n",
      "|          Modules           | Parameters |\n",
      "+----------------------------+------------+\n",
      "| conv_blocks.0.conv1.weight |    704     |\n",
      "|  conv_blocks.0.conv1.bias  |     64     |\n",
      "| conv_blocks.0.conv2.weight |   45056    |\n",
      "|  conv_blocks.0.conv2.bias  |     64     |\n",
      "| conv_blocks.1.conv1.weight |   45056    |\n",
      "|  conv_blocks.1.conv1.bias  |     64     |\n",
      "| conv_blocks.1.conv2.weight |   45056    |\n",
      "|  conv_blocks.1.conv2.bias  |     64     |\n",
      "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
      "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
      "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
      "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
      "|         fc.weight          |    1024    |\n",
      "|          fc.bias           |     8      |\n",
      "+----------------------------+------------+\n",
      "Total Params: 302024\n",
      "EPOCH: 1/10 \n",
      "Train Loss: 1.2429 Train Acc (M): 0.0759 Train Prc (M): 0.1231 Train Rcl (M): 0.1135 Train F1 (M): 0.1139 Train Acc (W): 0.3096 Train Prc (W): 0.4941 Train Rcl (W): 0.4653 Train F1 (W): 0.4630 \n",
      "Valid Loss: 0.7383 Valid Acc (M): 0.0706 Valid Prc (M): 0.1095 Valid Rcl (M): 0.1112 Valid F1 (M): 0.1082 Valid Acc (W): 0.2877 Valid Prc (W): 0.4408 Valid Rcl (W): 0.4545 Valid F1 (W): 0.4390\n",
      "Performance improved... (0.0->0.4326111214431839)\n",
      "EPOCH: 2/10 \n",
      "Train Loss: 0.7878 Train Acc (M): 0.0869 Train Prc (M): 0.1288 Train Rcl (M): 0.1288 Train F1 (M): 0.1287 Train Acc (W): 0.3500 Train Prc (W): 0.5169 Train Rcl (W): 0.5187 Train F1 (W): 0.5173 \n",
      "Valid Loss: 0.6958 Valid Acc (M): 0.1001 Valid Prc (M): 0.1431 Valid Rcl (M): 0.1427 Valid F1 (M): 0.1426 Valid Acc (W): 0.4028 Valid Prc (W): 0.5734 Valid Rcl (W): 0.5751 Valid F1 (W): 0.5728\n",
      "Performance improved... (0.4326111214431839->0.570250735663046)\n",
      "EPOCH: 3/10 \n",
      "Train Loss: 0.7421 Train Acc (M): 0.0890 Train Prc (M): 0.1311 Train Rcl (M): 0.1310 Train F1 (M): 0.1309 Train Acc (W): 0.3582 Train Prc (W): 0.5259 Train Rcl (W): 0.5276 Train F1 (W): 0.5262 \n",
      "Valid Loss: 0.6677 Valid Acc (M): 0.1015 Valid Prc (M): 0.1718 Valid Rcl (M): 0.1501 Valid F1 (M): 0.1398 Valid Acc (W): 0.4151 Valid Prc (W): 0.6816 Valid Rcl (W): 0.6195 Valid F1 (W): 0.5684\n",
      "EPOCH: 4/10 \n",
      "Train Loss: 0.7239 Train Acc (M): 0.0910 Train Prc (M): 0.1334 Train Rcl (M): 0.1332 Train F1 (M): 0.1330 Train Acc (W): 0.3668 Train Prc (W): 0.5351 Train Rcl (W): 0.5375 Train F1 (W): 0.5349 \n",
      "Valid Loss: 0.6398 Valid Acc (M): 0.1170 Valid Prc (M): 0.1822 Valid Rcl (M): 0.1624 Valid F1 (M): 0.1567 Valid Acc (W): 0.4753 Valid Prc (W): 0.7226 Valid Rcl (W): 0.6660 Valid F1 (W): 0.6338\n",
      "Performance improved... (0.570250735663046->0.6269269169329075)\n",
      "EPOCH: 5/10 \n",
      "Train Loss: 0.6733 Train Acc (M): 0.1070 Train Prc (M): 0.1499 Train Rcl (M): 0.1496 Train F1 (M): 0.1496 Train Acc (W): 0.4301 Train Prc (W): 0.6006 Train Rcl (W): 0.6016 Train F1 (W): 0.6005 \n",
      "Valid Loss: 0.5981 Valid Acc (M): 0.1350 Valid Prc (M): 0.1753 Valid Rcl (M): 0.1753 Valid F1 (M): 0.1753 Valid Acc (W): 0.5410 Valid Prc (W): 0.7022 Valid Rcl (W): 0.7019 Valid F1 (W): 0.7020\n",
      "Performance improved... (0.6269269169329075->0.7011333031597154)\n",
      "EPOCH: 6/10 \n",
      "Train Loss: 0.6159 Train Acc (M): 0.1247 Train Prc (M): 0.1666 Train Rcl (M): 0.1662 Train F1 (M): 0.1662 Train Acc (W): 0.5006 Train Prc (W): 0.6669 Train Rcl (W): 0.6675 Train F1 (W): 0.6666 \n",
      "Valid Loss: 0.5247 Valid Acc (M): 0.1512 Valid Prc (M): 0.1886 Valid Rcl (M): 0.1882 Valid F1 (M): 0.1884 Valid Acc (W): 0.6061 Valid Prc (W): 0.7546 Valid Rcl (W): 0.7548 Valid F1 (W): 0.7544\n",
      "Performance improved... (0.7011333031597154->0.7534066803293424)\n",
      "EPOCH: 7/10 \n",
      "Train Loss: 0.5800 Train Acc (M): 0.1358 Train Prc (M): 0.1766 Train Rcl (M): 0.1757 Train F1 (M): 0.1758 Train Acc (W): 0.5454 Train Prc (W): 0.7065 Train Rcl (W): 0.7065 Train F1 (W): 0.7051 \n",
      "Valid Loss: 0.5138 Valid Acc (M): 0.1494 Valid Prc (M): 0.1871 Valid Rcl (M): 0.1873 Valid F1 (M): 0.1870 Valid Acc (W): 0.5983 Valid Prc (W): 0.7500 Valid Rcl (W): 0.7484 Valid F1 (W): 0.7486\n",
      "EPOCH: 8/10 \n",
      "Train Loss: 0.5355 Train Acc (M): 0.1468 Train Prc (M): 0.1856 Train Rcl (M): 0.1847 Train F1 (M): 0.1849 Train Acc (W): 0.5891 Train Prc (W): 0.7423 Train Rcl (W): 0.7420 Train F1 (W): 0.7409 \n",
      "Valid Loss: 0.4945 Valid Acc (M): 0.1512 Valid Prc (M): 0.1903 Valid Rcl (M): 0.1880 Valid F1 (M): 0.1882 Valid Acc (W): 0.6070 Valid Prc (W): 0.7601 Valid Rcl (W): 0.7569 Valid F1 (W): 0.7547\n",
      "EPOCH: 9/10 \n",
      "Train Loss: 0.5035 Train Acc (M): 0.1555 Train Prc (M): 0.1922 Train Rcl (M): 0.1915 Train F1 (M): 0.1917 Train Acc (W): 0.6236 Train Prc (W): 0.7687 Train Rcl (W): 0.7685 Train F1 (W): 0.7678 \n",
      "Valid Loss: 0.4524 Valid Acc (M): 0.1562 Valid Prc (M): 0.2027 Valid Rcl (M): 0.1921 Valid F1 (M): 0.1918 Valid Acc (W): 0.6288 Valid Prc (W): 0.8059 Valid Rcl (W): 0.7780 Valid F1 (W): 0.7701\n",
      "Performance improved... (0.7534066803293424->0.7671862182116488)\n",
      "EPOCH: 10/10 \n",
      "Train Loss: 0.4676 Train Acc (M): 0.1632 Train Prc (M): 0.1982 Train Rcl (M): 0.1972 Train F1 (M): 0.1974 Train Acc (W): 0.6544 Train Prc (W): 0.7923 Train Rcl (W): 0.7915 Train F1 (W): 0.7908 \n",
      "Valid Loss: 0.4360 Valid Acc (M): 0.1684 Valid Prc (M): 0.2012 Valid Rcl (M): 0.2012 Valid F1 (M): 0.2012 Valid Acc (W): 0.6744 Valid Prc (W): 0.8054 Valid Rcl (W): 0.8055 Valid F1 (W): 0.8054\n",
      "Performance improved... (0.7671862182116488->0.8047629302609383)\n",
      "\n",
      "Fold 7/10\n",
      "+----------------------------+------------+\n",
      "|          Modules           | Parameters |\n",
      "+----------------------------+------------+\n",
      "| conv_blocks.0.conv1.weight |    704     |\n",
      "|  conv_blocks.0.conv1.bias  |     64     |\n",
      "| conv_blocks.0.conv2.weight |   45056    |\n",
      "|  conv_blocks.0.conv2.bias  |     64     |\n",
      "| conv_blocks.1.conv1.weight |   45056    |\n",
      "|  conv_blocks.1.conv1.bias  |     64     |\n",
      "| conv_blocks.1.conv2.weight |   45056    |\n",
      "|  conv_blocks.1.conv2.bias  |     64     |\n",
      "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
      "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
      "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
      "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
      "|         fc.weight          |    1024    |\n",
      "|          fc.bias           |     8      |\n",
      "+----------------------------+------------+\n",
      "Total Params: 302024\n",
      "EPOCH: 1/10 \n",
      "Train Loss: 1.1714 Train Acc (M): 0.0784 Train Prc (M): 0.1256 Train Rcl (M): 0.1185 Train F1 (M): 0.1189 Train Acc (W): 0.3110 Train Prc (W): 0.5040 Train Rcl (W): 0.4670 Train F1 (W): 0.4727 \n",
      "Valid Loss: 0.7370 Valid Acc (M): 0.0775 Valid Prc (M): 0.1426 Valid Rcl (M): 0.1335 Valid F1 (M): 0.1130 Valid Acc (W): 0.3005 Valid Prc (W): 0.5752 Valid Rcl (W): 0.5116 Valid F1 (W): 0.4409\n",
      "Performance improved... (0.0->0.4520218864253008)\n",
      "EPOCH: 2/10 \n",
      "Train Loss: 0.7569 Train Acc (M): 0.0874 Train Prc (M): 0.1294 Train Rcl (M): 0.1293 Train F1 (M): 0.1292 Train Acc (W): 0.3520 Train Prc (W): 0.5191 Train Rcl (W): 0.5210 Train F1 (W): 0.5194 \n",
      "Valid Loss: 0.7106 Valid Acc (M): 0.0782 Valid Prc (M): 0.1510 Valid Rcl (M): 0.1359 Valid F1 (M): 0.1132 Valid Acc (W): 0.3028 Valid Prc (W): 0.6109 Valid Rcl (W): 0.5201 Valid F1 (W): 0.4409\n",
      "Performance improved... (0.4520218864253008->0.45267187635403444)\n",
      "EPOCH: 3/10 \n",
      "Train Loss: 0.7175 Train Acc (M): 0.0973 Train Prc (M): 0.1401 Train Rcl (M): 0.1399 Train F1 (M): 0.1399 Train Acc (W): 0.3916 Train Prc (W): 0.5616 Train Rcl (W): 0.5629 Train F1 (W): 0.5617 \n",
      "Valid Loss: 0.6591 Valid Acc (M): 0.1065 Valid Prc (M): 0.1515 Valid Rcl (M): 0.1509 Valid F1 (M): 0.1493 Valid Acc (W): 0.4249 Valid Prc (W): 0.6087 Valid Rcl (W): 0.5983 Valid F1 (W): 0.5962\n",
      "Performance improved... (0.45267187635403444->0.5973566308243727)\n",
      "EPOCH: 4/10 \n",
      "Train Loss: 0.6660 Train Acc (M): 0.1119 Train Prc (M): 0.1546 Train Rcl (M): 0.1544 Train F1 (M): 0.1544 Train Acc (W): 0.4494 Train Prc (W): 0.6194 Train Rcl (W): 0.6202 Train F1 (W): 0.6194 \n",
      "Valid Loss: 0.6130 Valid Acc (M): 0.1189 Valid Prc (M): 0.1661 Valid Rcl (M): 0.1638 Valid F1 (M): 0.1610 Valid Acc (W): 0.4734 Valid Prc (W): 0.6690 Valid Rcl (W): 0.6469 Valid F1 (W): 0.6418\n",
      "Performance improved... (0.5973566308243727->0.6438526012994099)\n",
      "EPOCH: 5/10 \n",
      "Train Loss: 0.5863 Train Acc (M): 0.1326 Train Prc (M): 0.1736 Train Rcl (M): 0.1730 Train F1 (M): 0.1731 Train Acc (W): 0.5322 Train Prc (W): 0.6946 Train Rcl (W): 0.6949 Train F1 (W): 0.6941 \n",
      "Valid Loss: 0.5481 Valid Acc (M): 0.1388 Valid Prc (M): 0.1793 Valid Rcl (M): 0.1782 Valid F1 (M): 0.1783 Valid Acc (W): 0.5576 Valid Prc (W): 0.7170 Valid Rcl (W): 0.7167 Valid F1 (W): 0.7153\n",
      "Performance improved... (0.6438526012994099->0.7133696320683044)\n",
      "EPOCH: 6/10 \n",
      "Train Loss: 0.5540 Train Acc (M): 0.1441 Train Prc (M): 0.1835 Train Rcl (M): 0.1825 Train F1 (M): 0.1826 Train Acc (W): 0.5782 Train Prc (W): 0.7336 Train Rcl (W): 0.7333 Train F1 (W): 0.7321 \n",
      "Valid Loss: 0.5136 Valid Acc (M): 0.1457 Valid Prc (M): 0.1859 Valid Rcl (M): 0.1837 Valid F1 (M): 0.1839 Valid Acc (W): 0.5854 Valid Prc (W): 0.7425 Valid Rcl (W): 0.7400 Valid F1 (W): 0.7375\n",
      "Performance improved... (0.7133696320683044->0.7354116924756122)\n",
      "EPOCH: 7/10 \n",
      "Train Loss: 0.5109 Train Acc (M): 0.1510 Train Prc (M): 0.1888 Train Rcl (M): 0.1880 Train F1 (M): 0.1882 Train Acc (W): 0.6058 Train Prc (W): 0.7552 Train Rcl (W): 0.7549 Train F1 (W): 0.7541 \n",
      "Valid Loss: 0.5055 Valid Acc (M): 0.1524 Valid Prc (M): 0.2004 Valid Rcl (M): 0.1891 Valid F1 (M): 0.1887 Valid Acc (W): 0.6139 Valid Prc (W): 0.7962 Valid Rcl (W): 0.7674 Valid F1 (W): 0.7583\n",
      "Performance improved... (0.7354116924756122->0.7548991897493877)\n",
      "EPOCH: 8/10 \n",
      "Train Loss: 0.4916 Train Acc (M): 0.1566 Train Prc (M): 0.1937 Train Rcl (M): 0.1922 Train F1 (M): 0.1925 Train Acc (W): 0.6284 Train Prc (W): 0.7739 Train Rcl (W): 0.7725 Train F1 (W): 0.7713 \n",
      "Valid Loss: 0.4730 Valid Acc (M): 0.1555 Valid Prc (M): 0.1931 Valid Rcl (M): 0.1913 Valid F1 (M): 0.1916 Valid Acc (W): 0.6242 Valid Prc (W): 0.7715 Valid Rcl (W): 0.7696 Valid F1 (W): 0.7680\n",
      "Performance improved... (0.7548991897493877->0.7662799816857289)\n",
      "EPOCH: 9/10 \n",
      "Train Loss: 0.4446 Train Acc (M): 0.1689 Train Prc (M): 0.2025 Train Rcl (M): 0.2013 Train F1 (M): 0.2015 Train Acc (W): 0.6772 Train Prc (W): 0.8090 Train Rcl (W): 0.8080 Train F1 (W): 0.8073 \n",
      "Valid Loss: 0.4378 Valid Acc (M): 0.1622 Valid Prc (M): 0.1998 Valid Rcl (M): 0.1962 Valid F1 (M): 0.1966 Valid Acc (W): 0.6514 Valid Prc (W): 0.7968 Valid Rcl (W): 0.7907 Valid F1 (W): 0.7882\n",
      "Performance improved... (0.7662799816857289->0.7862805504210311)\n",
      "EPOCH: 10/10 \n",
      "Train Loss: 0.4269 Train Acc (M): 0.1691 Train Prc (M): 0.2025 Train Rcl (M): 0.2014 Train F1 (M): 0.2017 Train Acc (W): 0.6780 Train Prc (W): 0.8093 Train Rcl (W): 0.8085 Train F1 (W): 0.8078 \n",
      "Valid Loss: 0.4399 Valid Acc (M): 0.1637 Valid Prc (M): 0.1983 Valid Rcl (M): 0.1976 Valid F1 (M): 0.1978 Valid Acc (W): 0.6565 Valid Prc (W): 0.7929 Valid Rcl (W): 0.7928 Valid F1 (W): 0.7924\n",
      "Performance improved... (0.7862805504210311->0.7912433347744632)\n",
      "\n",
      "Fold 8/10\n",
      "+----------------------------+------------+\n",
      "|          Modules           | Parameters |\n",
      "+----------------------------+------------+\n",
      "| conv_blocks.0.conv1.weight |    704     |\n",
      "|  conv_blocks.0.conv1.bias  |     64     |\n",
      "| conv_blocks.0.conv2.weight |   45056    |\n",
      "|  conv_blocks.0.conv2.bias  |     64     |\n",
      "| conv_blocks.1.conv1.weight |   45056    |\n",
      "|  conv_blocks.1.conv1.bias  |     64     |\n",
      "| conv_blocks.1.conv2.weight |   45056    |\n",
      "|  conv_blocks.1.conv2.bias  |     64     |\n",
      "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
      "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
      "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
      "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
      "|         fc.weight          |    1024    |\n",
      "|          fc.bias           |     8      |\n",
      "+----------------------------+------------+\n",
      "Total Params: 302024\n",
      "EPOCH: 1/10 \n",
      "Train Loss: 1.1569 Train Acc (M): 0.0800 Train Prc (M): 0.1252 Train Rcl (M): 0.1200 Train F1 (M): 0.1192 Train Acc (W): 0.3257 Train Prc (W): 0.5024 Train Rcl (W): 0.4905 Train F1 (W): 0.4831 \n",
      "Valid Loss: 0.7078 Valid Acc (M): 0.0784 Valid Prc (M): 0.1209 Valid Rcl (M): 0.1217 Valid F1 (M): 0.1162 Valid Acc (W): 0.3209 Valid Prc (W): 0.4859 Valid Rcl (W): 0.5011 Valid F1 (W): 0.4734\n",
      "Performance improved... (0.0->0.46487056567593477)\n",
      "EPOCH: 2/10 \n",
      "Train Loss: 0.7452 Train Acc (M): 0.0883 Train Prc (M): 0.1305 Train Rcl (M): 0.1304 Train F1 (M): 0.1300 Train Acc (W): 0.3562 Train Prc (W): 0.5235 Train Rcl (W): 0.5264 Train F1 (W): 0.5231 \n",
      "Valid Loss: 0.6841 Valid Acc (M): 0.0971 Valid Prc (M): 0.1407 Valid Rcl (M): 0.1398 Valid F1 (M): 0.1391 Valid Acc (W): 0.3924 Valid Prc (W): 0.5638 Valid Rcl (W): 0.5666 Valid F1 (W): 0.5605\n",
      "Performance improved... (0.46487056567593477->0.5563156329360086)\n",
      "EPOCH: 3/10 \n",
      "Train Loss: 0.7193 Train Acc (M): 0.0914 Train Prc (M): 0.1338 Train Rcl (M): 0.1336 Train F1 (M): 0.1335 Train Acc (W): 0.3680 Train Prc (W): 0.5365 Train Rcl (W): 0.5384 Train F1 (W): 0.5367 \n",
      "Valid Loss: 0.6700 Valid Acc (M): 0.1067 Valid Prc (M): 0.1503 Valid Rcl (M): 0.1502 Valid F1 (M): 0.1496 Valid Acc (W): 0.4267 Valid Prc (W): 0.6035 Valid Rcl (W): 0.5983 Valid F1 (W): 0.5981\n",
      "Performance improved... (0.5563156329360086->0.5982925084927588)\n",
      "EPOCH: 4/10 \n",
      "Train Loss: 0.7052 Train Acc (M): 0.0977 Train Prc (M): 0.1405 Train Rcl (M): 0.1403 Train F1 (M): 0.1402 Train Acc (W): 0.3931 Train Prc (W): 0.5632 Train Rcl (W): 0.5647 Train F1 (W): 0.5631 \n",
      "Valid Loss: 0.6569 Valid Acc (M): 0.0946 Valid Prc (M): 0.1504 Valid Rcl (M): 0.1414 Valid F1 (M): 0.1332 Valid Acc (W): 0.3871 Valid Prc (W): 0.5997 Valid Rcl (W): 0.5835 Valid F1 (W): 0.5421\n",
      "EPOCH: 5/10 \n",
      "Train Loss: 0.6840 Train Acc (M): 0.1029 Train Prc (M): 0.1459 Train Rcl (M): 0.1456 Train F1 (M): 0.1455 Train Acc (W): 0.4141 Train Prc (W): 0.5847 Train Rcl (W): 0.5861 Train F1 (W): 0.5844 \n",
      "Valid Loss: 0.6499 Valid Acc (M): 0.1189 Valid Prc (M): 0.1661 Valid Rcl (M): 0.1638 Valid F1 (M): 0.1610 Valid Acc (W): 0.4734 Valid Prc (W): 0.6690 Valid Rcl (W): 0.6469 Valid F1 (W): 0.6418\n",
      "Performance improved... (0.5982925084927588->0.6438526012994099)\n",
      "EPOCH: 6/10 \n",
      "Train Loss: 0.6625 Train Acc (M): 0.1105 Train Prc (M): 0.1533 Train Rcl (M): 0.1530 Train F1 (M): 0.1530 Train Acc (W): 0.4439 Train Prc (W): 0.6141 Train Rcl (W): 0.6150 Train F1 (W): 0.6140 \n",
      "Valid Loss: 0.6012 Valid Acc (M): 0.1329 Valid Prc (M): 0.1736 Valid Rcl (M): 0.1733 Valid F1 (M): 0.1734 Valid Acc (W): 0.5333 Valid Prc (W): 0.6951 Valid Rcl (W): 0.6956 Valid F1 (W): 0.6952\n",
      "Performance improved... (0.6438526012994099->0.6936859147328656)\n",
      "EPOCH: 7/10 \n",
      "Train Loss: 0.6257 Train Acc (M): 0.1229 Train Prc (M): 0.1649 Train Rcl (M): 0.1646 Train F1 (M): 0.1646 Train Acc (W): 0.4934 Train Prc (W): 0.6603 Train Rcl (W): 0.6609 Train F1 (W): 0.6601 \n",
      "Valid Loss: 0.5465 Valid Acc (M): 0.1416 Valid Prc (M): 0.1847 Valid Rcl (M): 0.1805 Valid F1 (M): 0.1804 Valid Acc (W): 0.5700 Valid Prc (W): 0.7367 Valid Rcl (W): 0.7294 Valid F1 (W): 0.7245\n",
      "Performance improved... (0.6936859147328656->0.7216214227911426)\n",
      "EPOCH: 8/10 \n",
      "Train Loss: 0.5927 Train Acc (M): 0.1317 Train Prc (M): 0.1733 Train Rcl (M): 0.1722 Train F1 (M): 0.1723 Train Acc (W): 0.5290 Train Prc (W): 0.6930 Train Rcl (W): 0.6928 Train F1 (W): 0.6911 \n",
      "Valid Loss: 0.5269 Valid Acc (M): 0.1438 Valid Prc (M): 0.1883 Valid Rcl (M): 0.1823 Valid F1 (M): 0.1821 Valid Acc (W): 0.5790 Valid Prc (W): 0.7503 Valid Rcl (W): 0.7378 Valid F1 (W): 0.7314\n",
      "Performance improved... (0.7216214227911426->0.7282213819691579)\n",
      "EPOCH: 9/10 \n",
      "Train Loss: 0.5526 Train Acc (M): 0.1432 Train Prc (M): 0.1823 Train Rcl (M): 0.1818 Train F1 (M): 0.1820 Train Acc (W): 0.5743 Train Prc (W): 0.7295 Train Rcl (W): 0.7297 Train F1 (W): 0.7292 \n",
      "Valid Loss: 0.4884 Valid Acc (M): 0.1582 Valid Prc (M): 0.1956 Valid Rcl (M): 0.1933 Valid F1 (M): 0.1936 Valid Acc (W): 0.6351 Valid Prc (W): 0.7811 Valid Rcl (W): 0.7780 Valid F1 (W): 0.7761\n",
      "Performance improved... (0.7282213819691579->0.7743822940185073)\n",
      "EPOCH: 10/10 \n",
      "Train Loss: 0.5409 Train Acc (M): 0.1463 Train Prc (M): 0.1850 Train Rcl (M): 0.1843 Train F1 (M): 0.1845 Train Acc (W): 0.5870 Train Prc (W): 0.7401 Train Rcl (W): 0.7401 Train F1 (W): 0.7393 \n",
      "Valid Loss: 0.5245 Valid Acc (M): 0.1486 Valid Prc (M): 0.1899 Valid Rcl (M): 0.1882 Valid F1 (M): 0.1864 Valid Acc (W): 0.5933 Valid Prc (W): 0.7643 Valid Rcl (W): 0.7463 Valid F1 (W): 0.7446\n",
      "\n",
      "Fold 9/10\n",
      "+----------------------------+------------+\n",
      "|          Modules           | Parameters |\n",
      "+----------------------------+------------+\n",
      "| conv_blocks.0.conv1.weight |    704     |\n",
      "|  conv_blocks.0.conv1.bias  |     64     |\n",
      "| conv_blocks.0.conv2.weight |   45056    |\n",
      "|  conv_blocks.0.conv2.bias  |     64     |\n",
      "| conv_blocks.1.conv1.weight |   45056    |\n",
      "|  conv_blocks.1.conv1.bias  |     64     |\n",
      "| conv_blocks.1.conv2.weight |   45056    |\n",
      "|  conv_blocks.1.conv2.bias  |     64     |\n",
      "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
      "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
      "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
      "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
      "|         fc.weight          |    1024    |\n",
      "|          fc.bias           |     8      |\n",
      "+----------------------------+------------+\n",
      "Total Params: 302024\n",
      "EPOCH: 1/10 \n",
      "Train Loss: 1.2458 Train Acc (M): 0.0768 Train Prc (M): 0.1258 Train Rcl (M): 0.1111 Train F1 (M): 0.1160 Train Acc (W): 0.3119 Train Prc (W): 0.5051 Train Rcl (W): 0.4528 Train F1 (W): 0.4695 \n",
      "Valid Loss: 0.7273 Valid Acc (M): 0.0658 Valid Prc (M): 0.0908 Valid Rcl (M): 0.1236 Valid F1 (M): 0.0869 Valid Acc (W): 0.2787 Valid Prc (W): 0.3731 Valid Rcl (W): 0.5233 Valid F1 (W): 0.3676\n",
      "Performance improved... (0.0->0.34750152065323575)\n",
      "EPOCH: 2/10 \n",
      "Train Loss: 0.7876 Train Acc (M): 0.0874 Train Prc (M): 0.1294 Train Rcl (M): 0.1294 Train F1 (M): 0.1291 Train Acc (W): 0.3523 Train Prc (W): 0.5193 Train Rcl (W): 0.5216 Train F1 (W): 0.5195 \n",
      "Valid Loss: 0.6970 Valid Acc (M): 0.0831 Valid Prc (M): 0.1436 Valid Rcl (M): 0.1333 Valid F1 (M): 0.1173 Valid Acc (W): 0.3434 Valid Prc (W): 0.5727 Valid Rcl (W): 0.5551 Valid F1 (W): 0.4817\n",
      "Performance improved... (0.34750152065323575->0.4690493025647619)\n",
      "EPOCH: 3/10 \n",
      "Train Loss: 0.7602 Train Acc (M): 0.0883 Train Prc (M): 0.1306 Train Rcl (M): 0.1304 Train F1 (M): 0.1300 Train Acc (W): 0.3565 Train Prc (W): 0.5238 Train Rcl (W): 0.5270 Train F1 (W): 0.5233 \n",
      "Valid Loss: 0.6868 Valid Acc (M): 0.0818 Valid Prc (M): 0.1415 Valid Rcl (M): 0.1321 Valid F1 (M): 0.1154 Valid Acc (W): 0.3383 Valid Prc (W): 0.5649 Valid Rcl (W): 0.5508 Valid F1 (W): 0.4748\n",
      "EPOCH: 4/10 \n",
      "Train Loss: 0.7071 Train Acc (M): 0.1007 Train Prc (M): 0.1439 Train Rcl (M): 0.1434 Train F1 (M): 0.1432 Train Acc (W): 0.4057 Train Prc (W): 0.5764 Train Rcl (W): 0.5782 Train F1 (W): 0.5756 \n",
      "Valid Loss: 0.6372 Valid Acc (M): 0.1282 Valid Prc (M): 0.1707 Valid Rcl (M): 0.1704 Valid F1 (M): 0.1695 Valid Acc (W): 0.5122 Valid Prc (W): 0.6857 Valid Rcl (W): 0.6780 Valid F1 (W): 0.6774\n",
      "Performance improved... (0.4690493025647619->0.6778214869501176)\n",
      "EPOCH: 5/10 \n",
      "Train Loss: 0.6648 Train Acc (M): 0.1130 Train Prc (M): 0.1559 Train Rcl (M): 0.1554 Train F1 (M): 0.1554 Train Acc (W): 0.4543 Train Prc (W): 0.6243 Train Rcl (W): 0.6252 Train F1 (W): 0.6238 \n",
      "Valid Loss: 0.5874 Valid Acc (M): 0.1321 Valid Prc (M): 0.1729 Valid Rcl (M): 0.1727 Valid F1 (M): 0.1728 Valid Acc (W): 0.5301 Valid Prc (W): 0.6924 Valid Rcl (W): 0.6928 Valid F1 (W): 0.6925\n",
      "Performance improved... (0.6778214869501176->0.6910980822264048)\n",
      "EPOCH: 6/10 \n",
      "Train Loss: 0.5875 Train Acc (M): 0.1363 Train Prc (M): 0.1768 Train Rcl (M): 0.1761 Train F1 (M): 0.1763 Train Acc (W): 0.5470 Train Prc (W): 0.7072 Train Rcl (W): 0.7075 Train F1 (W): 0.7066 \n",
      "Valid Loss: 0.6230 Valid Acc (M): 0.1223 Valid Prc (M): 0.1799 Valid Rcl (M): 0.1659 Valid F1 (M): 0.1624 Valid Acc (W): 0.4958 Valid Prc (W): 0.7148 Valid Rcl (W): 0.6780 Valid F1 (W): 0.6556\n",
      "EPOCH: 7/10 \n",
      "Train Loss: 0.5470 Train Acc (M): 0.1443 Train Prc (M): 0.1835 Train Rcl (M): 0.1827 Train F1 (M): 0.1829 Train Acc (W): 0.5790 Train Prc (W): 0.7339 Train Rcl (W): 0.7338 Train F1 (W): 0.7329 \n",
      "Valid Loss: 0.5796 Valid Acc (M): 0.1380 Valid Prc (M): 0.1823 Valid Rcl (M): 0.1776 Valid F1 (M): 0.1773 Valid Acc (W): 0.5555 Valid Prc (W): 0.7269 Valid Rcl (W): 0.7182 Valid F1 (W): 0.7123\n",
      "Performance improved... (0.6910980822264048->0.7092290233678409)\n",
      "EPOCH: 8/10 \n",
      "Train Loss: 0.5111 Train Acc (M): 0.1554 Train Prc (M): 0.1922 Train Rcl (M): 0.1914 Train F1 (M): 0.1916 Train Acc (W): 0.6233 Train Prc (W): 0.7686 Train Rcl (W): 0.7683 Train F1 (W): 0.7676 \n",
      "Valid Loss: 0.5421 Valid Acc (M): 0.1472 Valid Prc (M): 0.1882 Valid Rcl (M): 0.1849 Valid F1 (M): 0.1850 Valid Acc (W): 0.5917 Valid Prc (W): 0.7512 Valid Rcl (W): 0.7458 Valid F1 (W): 0.7423\n",
      "Performance improved... (0.7092290233678409->0.7400451616456463)\n",
      "EPOCH: 9/10 \n",
      "Train Loss: 0.4747 Train Acc (M): 0.1631 Train Prc (M): 0.1980 Train Rcl (M): 0.1971 Train F1 (M): 0.1973 Train Acc (W): 0.6539 Train Prc (W): 0.7917 Train Rcl (W): 0.7911 Train F1 (W): 0.7904 \n",
      "Valid Loss: 0.5240 Valid Acc (M): 0.1489 Valid Prc (M): 0.1868 Valid Rcl (M): 0.1865 Valid F1 (M): 0.1866 Valid Acc (W): 0.5972 Valid Prc (W): 0.7477 Valid Rcl (W): 0.7479 Valid F1 (W): 0.7475\n",
      "Performance improved... (0.7400451616456463->0.7463225165413365)\n",
      "EPOCH: 10/10 \n",
      "Train Loss: 0.4572 Train Acc (M): 0.1634 Train Prc (M): 0.1984 Train Rcl (M): 0.1973 Train F1 (M): 0.1975 Train Acc (W): 0.6551 Train Prc (W): 0.7930 Train Rcl (W): 0.7921 Train F1 (W): 0.7912 \n",
      "Valid Loss: 0.4774 Valid Acc (M): 0.1590 Valid Prc (M): 0.1956 Valid Rcl (M): 0.1940 Valid F1 (M): 0.1942 Valid Acc (W): 0.6379 Valid Prc (W): 0.7813 Valid Rcl (W): 0.7797 Valid F1 (W): 0.7784\n",
      "Performance improved... (0.7463225165413365->0.7769538349691021)\n",
      "\n",
      "Fold 10/10\n",
      "+----------------------------+------------+\n",
      "|          Modules           | Parameters |\n",
      "+----------------------------+------------+\n",
      "| conv_blocks.0.conv1.weight |    704     |\n",
      "|  conv_blocks.0.conv1.bias  |     64     |\n",
      "| conv_blocks.0.conv2.weight |   45056    |\n",
      "|  conv_blocks.0.conv2.bias  |     64     |\n",
      "| conv_blocks.1.conv1.weight |   45056    |\n",
      "|  conv_blocks.1.conv1.bias  |     64     |\n",
      "| conv_blocks.1.conv2.weight |   45056    |\n",
      "|  conv_blocks.1.conv2.bias  |     64     |\n",
      "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
      "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
      "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
      "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
      "|         fc.weight          |    1024    |\n",
      "|          fc.bias           |     8      |\n",
      "+----------------------------+------------+\n",
      "Total Params: 302024\n",
      "EPOCH: 1/10 \n",
      "Train Loss: 1.2221 Train Acc (M): 0.0826 Train Prc (M): 0.1285 Train Rcl (M): 0.1211 Train F1 (M): 0.1232 Train Acc (W): 0.3346 Train Prc (W): 0.5152 Train Rcl (W): 0.4918 Train F1 (W): 0.4973 \n",
      "Valid Loss: 0.7103 Valid Acc (M): 0.0662 Valid Prc (M): 0.0662 Valid Rcl (M): 0.1250 Valid F1 (M): 0.0866 Valid Acc (W): 0.2805 Valid Prc (W): 0.2805 Valid Rcl (W): 0.5297 Valid F1 (W): 0.3668\n",
      "Performance improved... (0.0->0.3462603878116343)\n",
      "EPOCH: 2/10 \n",
      "Train Loss: 0.7802 Train Acc (M): 0.0840 Train Prc (M): 0.1256 Train Rcl (M): 0.1256 Train F1 (M): 0.1252 Train Acc (W): 0.3387 Train Prc (W): 0.5039 Train Rcl (W): 0.5068 Train F1 (W): 0.5041 \n",
      "Valid Loss: 0.6707 Valid Acc (M): 0.0990 Valid Prc (M): 0.1698 Valid Rcl (M): 0.1480 Valid F1 (M): 0.1368 Valid Acc (W): 0.4059 Valid Prc (W): 0.6734 Valid Rcl (W): 0.6123 Valid F1 (W): 0.5573\n",
      "Performance improved... (0.3462603878116343->0.5471603151884997)\n",
      "EPOCH: 3/10 \n",
      "Train Loss: 0.7448 Train Acc (M): 0.0884 Train Prc (M): 0.1307 Train Rcl (M): 0.1305 Train F1 (M): 0.1301 Train Acc (W): 0.3567 Train Prc (W): 0.5241 Train Rcl (W): 0.5270 Train F1 (W): 0.5238 \n",
      "Valid Loss: 0.6587 Valid Acc (M): 0.1070 Valid Prc (M): 0.1672 Valid Rcl (M): 0.1531 Valid F1 (M): 0.1467 Valid Acc (W): 0.4358 Valid Prc (W): 0.6649 Valid Rcl (W): 0.6292 Valid F1 (W): 0.5948\n",
      "Performance improved... (0.5471603151884997->0.5869648920158214)\n",
      "EPOCH: 4/10 \n",
      "Train Loss: 0.7164 Train Acc (M): 0.0939 Train Prc (M): 0.1366 Train Rcl (M): 0.1363 Train F1 (M): 0.1360 Train Acc (W): 0.3783 Train Prc (W): 0.5477 Train Rcl (W): 0.5500 Train F1 (W): 0.5471 \n",
      "Valid Loss: 0.6517 Valid Acc (M): 0.1313 Valid Prc (M): 0.1729 Valid Rcl (M): 0.1728 Valid F1 (M): 0.1721 Valid Acc (W): 0.5249 Valid Prc (W): 0.6943 Valid Rcl (W): 0.6886 Valid F1 (W): 0.6884\n",
      "Performance improved... (0.5869648920158214->0.6885467399842891)\n",
      "EPOCH: 5/10 \n",
      "Train Loss: 0.6907 Train Acc (M): 0.1008 Train Prc (M): 0.1437 Train Rcl (M): 0.1435 Train F1 (M): 0.1434 Train Acc (W): 0.4056 Train Prc (W): 0.5761 Train Rcl (W): 0.5775 Train F1 (W): 0.5760 \n",
      "Valid Loss: 0.6061 Valid Acc (M): 0.1349 Valid Prc (M): 0.1772 Valid Rcl (M): 0.1750 Valid F1 (M): 0.1750 Valid Acc (W): 0.5427 Valid Prc (W): 0.7079 Valid Rcl (W): 0.7055 Valid F1 (W): 0.7023\n",
      "Performance improved... (0.6885467399842891->0.6998156104301355)\n",
      "EPOCH: 6/10 \n",
      "Train Loss: 0.6394 Train Acc (M): 0.1169 Train Prc (M): 0.1596 Train Rcl (M): 0.1591 Train F1 (M): 0.1591 Train Acc (W): 0.4699 Train Prc (W): 0.6390 Train Rcl (W): 0.6398 Train F1 (W): 0.6385 \n",
      "Valid Loss: 0.5678 Valid Acc (M): 0.1372 Valid Prc (M): 0.1923 Valid Rcl (M): 0.1779 Valid F1 (M): 0.1760 Valid Acc (W): 0.5545 Valid Prc (W): 0.7636 Valid Rcl (W): 0.7246 Valid F1 (W): 0.7088\n",
      "Performance improved... (0.6998156104301355->0.7041579881200339)\n",
      "EPOCH: 7/10 \n",
      "Train Loss: 0.5945 Train Acc (M): 0.1317 Train Prc (M): 0.1728 Train Rcl (M): 0.1722 Train F1 (M): 0.1723 Train Acc (W): 0.5286 Train Prc (W): 0.6916 Train Rcl (W): 0.6920 Train F1 (W): 0.6910 \n",
      "Valid Loss: 0.5319 Valid Acc (M): 0.1334 Valid Prc (M): 0.1942 Valid Rcl (M): 0.1753 Valid F1 (M): 0.1724 Valid Acc (W): 0.5399 Valid Prc (W): 0.7701 Valid Rcl (W): 0.7161 Valid F1 (W): 0.6949\n",
      "EPOCH: 8/10 \n",
      "Train Loss: 0.5659 Train Acc (M): 0.1399 Train Prc (M): 0.1804 Train Rcl (M): 0.1791 Train F1 (M): 0.1793 Train Acc (W): 0.5620 Train Prc (W): 0.7211 Train Rcl (W): 0.7204 Train F1 (W): 0.7188 \n",
      "Valid Loss: 0.4921 Valid Acc (M): 0.1611 Valid Prc (M): 0.1964 Valid Rcl (M): 0.1965 Valid F1 (M): 0.1960 Valid Acc (W): 0.6447 Valid Prc (W): 0.7881 Valid Rcl (W): 0.7839 Valid F1 (W): 0.7840\n",
      "Performance improved... (0.7041579881200339->0.7838827838827838)\n",
      "EPOCH: 9/10 \n",
      "Train Loss: 0.5430 Train Acc (M): 0.1442 Train Prc (M): 0.1837 Train Rcl (M): 0.1826 Train F1 (M): 0.1827 Train Acc (W): 0.5787 Train Prc (W): 0.7343 Train Rcl (W): 0.7338 Train F1 (W): 0.7325 \n",
      "Valid Loss: 0.4975 Valid Acc (M): 0.1537 Valid Prc (M): 0.1926 Valid Rcl (M): 0.1899 Valid F1 (M): 0.1901 Valid Acc (W): 0.6172 Valid Prc (W): 0.7688 Valid Rcl (W): 0.7648 Valid F1 (W): 0.7625\n",
      "EPOCH: 10/10 \n",
      "Train Loss: 0.5032 Train Acc (M): 0.1511 Train Prc (M): 0.1894 Train Rcl (M): 0.1880 Train F1 (M): 0.1882 Train Acc (W): 0.6065 Train Prc (W): 0.7571 Train Rcl (W): 0.7559 Train F1 (W): 0.7545 \n",
      "Valid Loss: 0.4549 Valid Acc (M): 0.1667 Valid Prc (M): 0.2001 Valid Rcl (M): 0.2000 Valid F1 (M): 0.2000 Valid Acc (W): 0.6680 Valid Prc (W): 0.8008 Valid Rcl (W): 0.8008 Valid F1 (W): 0.8008\n",
      "Performance improved... (0.7838827838827838->0.8000396603630725)\n",
      "\n",
      "K-FOLD VALIDATION RESULTS: \n",
      "Accuracy: 0.16103187883058245\n",
      "Precision: 0.19691147725979435\n",
      "Recall: 0.1958762976132476\n",
      "F1: 0.19570240473846884\n",
      "\n",
      "VALIDATION RESULTS (PER CLASS): \n",
      "\n",
      "Accuracy:\n",
      "   climbing_down: 0.6276915034349138\n",
      "   climbing_up: 0.6605635272097459\n",
      "   jumping: 0.0\n",
      "   lying: 0.0\n",
      "   running: 0.0\n",
      "   sitting: 0.0\n",
      "   standing: 0.0\n",
      "   walking: 0.0\n",
      "\n",
      "Precision:\n",
      "   climbing_down: 0.7777471393818141\n",
      "   climbing_up: 0.7975446786965408\n",
      "   jumping: 0.0\n",
      "   lying: 0.0\n",
      "   running: 0.0\n",
      "   sitting: 0.0\n",
      "   standing: 0.0\n",
      "   walking: 0.0\n",
      "\n",
      "Recall:\n",
      "   climbing_down: 0.7700016159657416\n",
      "   climbing_up: 0.7970087649402391\n",
      "   jumping: 0.0\n",
      "   lying: 0.0\n",
      "   running: 0.0\n",
      "   sitting: 0.0\n",
      "   standing: 0.0\n",
      "   walking: 0.0\n",
      "\n",
      "F1:\n",
      "   climbing_down: 0.7709998831208004\n",
      "   climbing_up: 0.7946193547869502\n",
      "   jumping: 0.0\n",
      "   lying: 0.0\n",
      "   running: 0.0\n",
      "   sitting: 0.0\n",
      "   standing: 0.0\n",
      "   walking: 0.0\n",
      "\n",
      "GENERALIZATION GAP ANALYSIS: \n",
      "\n",
      "Accuracy: [-0.01947217  0.00309436  0.          0.          0.          0.\n",
      "  0.          0.        ]\n",
      "Precision: [ 0.00837946 -0.02439385  0.          0.          0.          0.\n",
      "  0.          0.        ]\n",
      "Recall: [-0.04173755  0.02668745  0.          0.          0.          0.\n",
      "  0.          0.        ]\n",
      "F1: [-0.01495446  0.00297657  0.          0.          0.          0.\n",
      "  0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "# number of splits, i.e. folds\n",
    "config['splits_kfold'] = 10\n",
    "\n",
    "# in order to get reproducible results, we need to seed torch and other random parts of our implementation\n",
    "seed_torch(config['seed'])\n",
    "\n",
    "# needed for saving results\n",
    "log_date = time.strftime('%Y%m%d')\n",
    "log_timestamp = time.strftime('%H%M%S')\n",
    "\n",
    "# define the stratified k-fold object; it is already imported for you\n",
    "# pass it the number of splits, i.e. folds, and seed as well as set shuffling to true\n",
    "skf = StratifiedKFold(n_splits=config['splits_kfold'], shuffle=True, random_state=config['seed'])\n",
    "    \n",
    "print(train_valid_data.shape)\n",
    "\n",
    "# apply the sliding window on top of both the train_valid_data; use the \"apply_sliding_window\" function\n",
    "# found in data_processing.sliding_window\n",
    "X_train_valid, y_train_valid = apply_sliding_window(train_valid_data[:, :-1], train_valid_data[:,-1], sliding_window_size= config['sw_length'], unit=config['sw_unit'], sampling_rate=config['sampling_rate'], sliding_window_overlap=config['sw_overlap'])\n",
    "\n",
    "print(X_train_valid.shape, y_train_valid.shape)\n",
    "\n",
    "# (optional) omit the first feature column (subject_identifier) from the train _valid_data\n",
    "# you can do it if you want to as it is not a useful feature\n",
    "X_train_valid = X_train_valid[:, :, 1:]\n",
    "\n",
    "# result objects used for accumulating the scores across folds; add each fold result to these objects so that they\n",
    "# are averaged at the end of the k-fold loop\n",
    "kfold_accuracy = np.zeros(config['nb_classes'])\n",
    "kfold_precision = np.zeros(config['nb_classes'])\n",
    "kfold_recall = np.zeros(config['nb_classes'])\n",
    "kfold_f1 = np.zeros(config['nb_classes'])\n",
    "    \n",
    "kfold_accuracy_gap = 0\n",
    "kfold_precision_gap = 0\n",
    "kfold_recall_gap = 0\n",
    "kfold_f1_gap = 0\n",
    "\n",
    "# k-fold validation loop; for each loop iteration return fold identifier and indeces which can be used to split\n",
    "# the train + valid data into train and validation data according to the current fold\n",
    "for j, (train_index, valid_index) in enumerate(skf.split(X_train_valid, y_train_valid)):\n",
    "    print('\\nFold {0}/{1}'.format(j + 1, config['splits_kfold']))\n",
    "    \n",
    "    # split the data into train and validation data; to do so, use the indeces produces by the split function\n",
    "    X_train, X_valid = X_train_valid[train_index],  X_train_valid[valid_index]\n",
    "    y_train, y_valid = y_train_valid[train_index],  y_train_valid[valid_index],\n",
    "    \n",
    "    # within the config file, set the parameters 'window_size' and 'nb_channels' accordingly\n",
    "    # window_size = size of the sliding window in units\n",
    "    # nb_channels = number of feature channels\n",
    "    config['window_size'] = X_train.shape[1]\n",
    "    config['nb_channels'] = X_train.shape[2]\n",
    "    \n",
    "    # define the network to be a DeepConvLSTM object; can be imported from model.DeepConvLSTM\n",
    "    # pass it the config object\n",
    "    net = DeepConvLSTM(config=config)\n",
    "    \n",
    "    # defines the loss and optimizer\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    opt = torch.optim.Adam(net.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "\n",
    "    # convert the features of the train and validation to float32 and labels to uint8 for GPU compatibility \n",
    "    X_train, y_train = X_train.astype(np.float32), y_train.astype(np.uint8)\n",
    "    X_valid, y_valid = X_valid.astype(np.float32), y_valid.astype(np.uint8) \n",
    "    \n",
    "    # feed the datasets into the train function; can be imported from model.train\n",
    "    kfold_net,_, val_output, train_output = train(X_train, y_train, X_valid, y_valid, network=net, optimizer=opt, loss=loss, config=config, log_date=log_date, log_timestamp=log_timestamp)\n",
    "        \n",
    "    # in the following validation and train evaluation metrics are calculated\n",
    "    cls = np.array(range(config['nb_classes']))\n",
    "    val_accuracy = jaccard_score(val_output[:, 1], val_output[:, 0], average=None, labels=cls)\n",
    "    val_precision = precision_score(val_output[:, 1], val_output[:, 0], average=None, labels=cls)\n",
    "    val_recall = recall_score(val_output[:, 1], val_output[:, 0], average=None, labels=cls)\n",
    "    val_f1 = f1_score(val_output[:, 1], val_output[:, 0], average=None, labels=cls)\n",
    "    train_accuracy = jaccard_score(train_output[:, 1], train_output[:, 0], average=None, labels=cls)\n",
    "    train_precision = precision_score(train_output[:, 1], train_output[:, 0], average=None, labels=cls)\n",
    "    train_recall = recall_score(train_output[:, 1], train_output[:, 0], average=None, labels=cls)\n",
    "    train_f1 = f1_score(train_output[:, 1], train_output[:, 0], average=None, labels=cls)\n",
    "    \n",
    "    # add up the fold results\n",
    "    kfold_accuracy += val_accuracy\n",
    "    kfold_precision += val_precision\n",
    "    kfold_recall += val_recall\n",
    "    kfold_f1 += val_f1\n",
    "\n",
    "    # add up the generalization gap results\n",
    "    kfold_accuracy_gap += train_accuracy - val_accuracy\n",
    "    kfold_precision_gap += train_precision - val_precision\n",
    "    kfold_recall_gap += train_recall - val_recall\n",
    "    kfold_f1_gap += train_f1 - val_f1\n",
    "    \n",
    "# the next bit prints out the average results across folds if you did everything correctly\n",
    "print(\"\\nK-FOLD VALIDATION RESULTS: \")\n",
    "print(\"Accuracy: {0}\".format(np.mean(kfold_accuracy / config['splits_kfold'])))\n",
    "print(\"Precision: {0}\".format(np.mean(kfold_precision / config['splits_kfold'])))\n",
    "print(\"Recall: {0}\".format(np.mean(kfold_recall / config['splits_kfold'])))\n",
    "print(\"F1: {0}\".format(np.mean(kfold_f1 / config['splits_kfold'])))\n",
    "    \n",
    "print(\"\\nVALIDATION RESULTS (PER CLASS): \")\n",
    "print(\"\\nAccuracy:\")\n",
    "for i, rslt in enumerate(kfold_accuracy / config['splits_kfold']):\n",
    "    print(\"   {0}: {1}\".format(class_names[i], rslt))\n",
    "print(\"\\nPrecision:\")\n",
    "for i, rslt in enumerate(kfold_precision / config['splits_kfold']):\n",
    "    print(\"   {0}: {1}\".format(class_names[i], rslt))\n",
    "print(\"\\nRecall:\")\n",
    "for i, rslt in enumerate(kfold_recall / config['splits_kfold']):\n",
    "    print(\"   {0}: {1}\".format(class_names[i], rslt))\n",
    "print(\"\\nF1:\")\n",
    "for i, rslt in enumerate(kfold_f1 / config['splits_kfold']):\n",
    "    print(\"   {0}: {1}\".format(class_names[i], rslt))\n",
    "    \n",
    "print(\"\\nGENERALIZATION GAP ANALYSIS: \")\n",
    "print(\"\\nAccuracy: {0}\".format(kfold_accuracy_gap / config['splits_kfold']))\n",
    "print(\"Precision: {0}\".format(kfold_precision_gap / config['splits_kfold']))\n",
    "print(\"Recall: {0}\".format(kfold_recall_gap / config['splits_kfold']))\n",
    "print(\"F1: {0}\".format(kfold_f1_gap / config['splits_kfold']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jI5ztrFyl9BL"
   },
   "source": [
    "### 5.3.3. Cross-Participant Cross-Validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "vgc5fBYMl9BL"
   },
   "source": [
    "Cross-participant cross-validation, also known as Leave-One-Subject-Out (LOSO) cross-validation is the most complex, but also most expressive validation method one can apply when dealing with multi-subject data. In general, it can be seen as a variation of the k-fold cross-validation with k being the number of subjects. Within each fold, you train your network on the data of all but one subject and validate it on the left-out subject. The process is repeated as many times as there are subjects so that each subject becomes the validation set exaclty once. This way, each subject is treated as the unseen data at least once. \n",
    "\n",
    "Leaving one subject out each fold ensures that the overall evaluation of the algorithm does not overfit on subject-specific traits, i.e. how subjects performed the activities individually. It is therefore a great method to obtain a model which is good at predicting activities no matter which person performs them, i.e. a more general model!\n",
    "\n",
    "The next task will lead you through the implementation of the cross-participant cross-validation loop."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xxmMLN71l9BM"
   },
   "source": [
    "#### Task 4: Implementing the cross-participant CV loop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3yaGaXanl9BM"
   },
   "source": [
    "1. Define a loop which iterates over the identifiers of all subjects. (`lines 8-10`)\n",
    "2. Define the `train` data to be everything but the current subject's data and the `valid` data to be the current subject's data by filtering the `train_valid_data`. (`lines 12-15`)\n",
    "3. Apply the `apply_sliding_window()` function on top of the filtered datasets you just defined. (`lines 19-27`)\n",
    "4. (*Optional*) Omit the first feature column (subject_identifier) from the train and validation dataset. (`lines 29-31`)\n",
    "5. Within the `config` object, set the parameters `window_size` and `nb_channels` accordingly. (`lines 51-55`)\n",
    "6. Define the `DeepConvLSTM` object. It is already imported for you. Also define the `optimizer` being the [Adam optimizer](https://pytorch.org/docs/stable/optim.html) and `criterion` being the [Cross-Entropy Loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) (`lines 39-45`)\n",
    "7. Convert the feature columns of the train and validation to `float32` and label column to `uint8` for GPU compatibility. Use the [built-in function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html) of a pandas dataframe called `astype()`. (`lines 47-49`)\n",
    "8. Use both datasets to run the `train()` function. (`lines 51-52`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vcUekkJal9BM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " VALIDATING FOR SUBJECT 1 OF 3\n",
      "(107270, 5) (58306, 5)\n",
      "(3063, 50, 4) (3063,)\n",
      "(1665, 50, 4) (1665,)\n",
      "+----------------------------+------------+\n",
      "|          Modules           | Parameters |\n",
      "+----------------------------+------------+\n",
      "| conv_blocks.0.conv1.weight |    704     |\n",
      "|  conv_blocks.0.conv1.bias  |     64     |\n",
      "| conv_blocks.0.conv2.weight |   45056    |\n",
      "|  conv_blocks.0.conv2.bias  |     64     |\n",
      "| conv_blocks.1.conv1.weight |   45056    |\n",
      "|  conv_blocks.1.conv1.bias  |     64     |\n",
      "| conv_blocks.1.conv2.weight |   45056    |\n",
      "|  conv_blocks.1.conv2.bias  |     64     |\n",
      "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
      "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
      "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
      "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
      "|         fc.weight          |    1024    |\n",
      "|          fc.bias           |     8      |\n",
      "+----------------------------+------------+\n",
      "Total Params: 302024\n",
      "EPOCH: 1/10 \n",
      "Train Loss: 1.4535 Train Acc (M): 0.0715 Train Prc (M): 0.1230 Train Rcl (M): 0.1072 Train F1 (M): 0.1087 Train Acc (W): 0.2882 Train Prc (W): 0.4925 Train Rcl (W): 0.4329 Train F1 (W): 0.4374 \n",
      "Valid Loss: 0.7929 Valid Acc (M): 0.0825 Valid Prc (M): 0.1758 Valid Rcl (M): 0.1338 Valid F1 (M): 0.1106 Valid Acc (W): 0.3616 Valid Prc (W): 0.6877 Valid Rcl (W): 0.5928 Valid F1 (W): 0.4793\n",
      "Performance improved... (0.0->0.44225790513833996)\n",
      "EPOCH: 2/10 \n",
      "Train Loss: 0.7956 Train Acc (M): 0.0876 Train Prc (M): 0.1297 Train Rcl (M): 0.1297 Train F1 (M): 0.1297 Train Acc (W): 0.3507 Train Prc (W): 0.5191 Train Rcl (W): 0.5194 Train F1 (W): 0.5191 \n",
      "Valid Loss: 0.7270 Valid Acc (M): 0.0717 Valid Prc (M): 0.1525 Valid Rcl (M): 0.1349 Valid F1 (M): 0.1055 Valid Acc (W): 0.2666 Valid Prc (W): 0.6294 Valid Rcl (W): 0.4877 Valid F1 (W): 0.3968\n",
      "EPOCH: 3/10 \n",
      "Train Loss: 0.7723 Train Acc (M): 0.0867 Train Prc (M): 0.1287 Train Rcl (M): 0.1287 Train F1 (M): 0.1287 Train Acc (W): 0.3470 Train Prc (W): 0.5151 Train Rcl (W): 0.5152 Train F1 (W): 0.5152 \n",
      "Valid Loss: 0.7098 Valid Acc (M): 0.0814 Valid Prc (M): 0.1221 Valid Rcl (M): 0.1221 Valid F1 (M): 0.1221 Valid Acc (W): 0.3329 Valid Prc (W): 0.4969 Valid Rcl (W): 0.4967 Valid F1 (W): 0.4968\n",
      "Performance improved... (0.44225790513833996->0.4884818880641008)\n",
      "EPOCH: 4/10 \n",
      "Train Loss: 0.7376 Train Acc (M): 0.0941 Train Prc (M): 0.1367 Train Rcl (M): 0.1367 Train F1 (M): 0.1367 Train Acc (W): 0.3766 Train Prc (W): 0.5470 Train Rcl (W): 0.5472 Train F1 (W): 0.5471 \n",
      "Valid Loss: 0.6983 Valid Acc (M): 0.0863 Valid Prc (M): 0.1276 Valid Rcl (M): 0.1273 Valid F1 (M): 0.1262 Valid Acc (W): 0.3578 Valid Prc (W): 0.5180 Valid Rcl (W): 0.5297 Valid F1 (W): 0.5190\n",
      "Performance improved... (0.4884818880641008->0.5047408227404497)\n",
      "EPOCH: 5/10 \n",
      "Train Loss: 0.7175 Train Acc (M): 0.0949 Train Prc (M): 0.1377 Train Rcl (M): 0.1376 Train F1 (M): 0.1375 Train Acc (W): 0.3801 Train Prc (W): 0.5508 Train Rcl (W): 0.5511 Train F1 (W): 0.5506 \n",
      "Valid Loss: 0.7079 Valid Acc (M): 0.0905 Valid Prc (M): 0.1379 Valid Rcl (M): 0.1373 Valid F1 (M): 0.1328 Valid Acc (W): 0.3588 Valid Prc (W): 0.5612 Valid Rcl (W): 0.5327 Valid F1 (W): 0.5276\n",
      "Performance improved... (0.5047408227404497->0.5311414151358613)\n",
      "EPOCH: 6/10 \n",
      "Train Loss: 0.6849 Train Acc (M): 0.1082 Train Prc (M): 0.1512 Train Rcl (M): 0.1512 Train F1 (M): 0.1511 Train Acc (W): 0.4329 Train Prc (W): 0.6049 Train Rcl (W): 0.6043 Train F1 (W): 0.6043 \n",
      "Valid Loss: 0.6715 Valid Acc (M): 0.0985 Valid Prc (M): 0.1465 Valid Rcl (M): 0.1413 Valid F1 (M): 0.1379 Valid Acc (W): 0.4116 Valid Prc (W): 0.5887 Valid Rcl (W): 0.5964 Valid F1 (W): 0.5696\n",
      "Performance improved... (0.5311414151358613->0.5514604954267315)\n",
      "EPOCH: 7/10 \n",
      "Train Loss: 0.6413 Train Acc (M): 0.1222 Train Prc (M): 0.1642 Train Rcl (M): 0.1642 Train F1 (M): 0.1642 Train Acc (W): 0.4891 Train Prc (W): 0.6568 Train Rcl (W): 0.6569 Train F1 (W): 0.6568 \n",
      "Valid Loss: 0.6306 Valid Acc (M): 0.1254 Valid Prc (M): 0.1695 Valid Rcl (M): 0.1657 Valid F1 (M): 0.1660 Valid Acc (W): 0.5124 Valid Prc (W): 0.6790 Valid Rcl (W): 0.6805 Valid F1 (W): 0.6735\n",
      "Performance improved... (0.5514604954267315->0.6639762919261445)\n",
      "EPOCH: 8/10 \n",
      "Train Loss: 0.5993 Train Acc (M): 0.1309 Train Prc (M): 0.1719 Train Rcl (M): 0.1718 Train F1 (M): 0.1718 Train Acc (W): 0.5238 Train Prc (W): 0.6876 Train Rcl (W): 0.6876 Train F1 (W): 0.6874 \n",
      "Valid Loss: 0.6355 Valid Acc (M): 0.0988 Valid Prc (M): 0.1783 Valid Rcl (M): 0.1459 Valid F1 (M): 0.1340 Valid Acc (W): 0.4210 Valid Prc (W): 0.7002 Valid Rcl (W): 0.6324 Valid F1 (W): 0.5631\n",
      "EPOCH: 9/10 \n",
      "Train Loss: 0.5643 Train Acc (M): 0.1439 Train Prc (M): 0.1830 Train Rcl (M): 0.1826 Train F1 (M): 0.1827 Train Acc (W): 0.5761 Train Prc (W): 0.7318 Train Rcl (W): 0.7313 Train F1 (W): 0.7309 \n",
      "Valid Loss: 0.5828 Valid Acc (M): 0.1310 Valid Prc (M): 0.1819 Valid Rcl (M): 0.1706 Valid F1 (M): 0.1703 Valid Acc (W): 0.5380 Valid Prc (W): 0.7223 Valid Rcl (W): 0.7087 Valid F1 (W): 0.6931\n",
      "Performance improved... (0.6639762919261445->0.6810880189564101)\n",
      "EPOCH: 10/10 \n",
      "Train Loss: 0.5404 Train Acc (M): 0.1468 Train Prc (M): 0.1855 Train Rcl (M): 0.1850 Train F1 (M): 0.1850 Train Acc (W): 0.5878 Train Prc (W): 0.7418 Train Rcl (W): 0.7408 Train F1 (W): 0.7402 \n",
      "Valid Loss: 0.5613 Valid Acc (M): 0.1412 Valid Prc (M): 0.1804 Valid Rcl (M): 0.1801 Valid F1 (M): 0.1802 Valid Acc (W): 0.5710 Valid Prc (W): 0.7255 Valid Rcl (W): 0.7261 Valid F1 (W): 0.7258\n",
      "Performance improved... (0.6810880189564101->0.720845478905678)\n",
      "\n",
      "VALIDATION RESULTS FOR SUBJECT 1: \n",
      "\n",
      "Avg. Accuracy: 0.5649426476541766\n",
      "Avg. Precision: 0.7215102131111275\n",
      "Avg. Recall: 0.7203196648447883\n",
      "Avg. F1: 0.720845478905678\n",
      "\n",
      "VALIDATION RESULTS (PER CLASS): \n",
      "\n",
      "Accuracy:\n",
      "   climbing_down: 0.5179704016913319\n",
      "   climbing_up: 0.6119148936170212\n",
      "   jumping: 0.0\n",
      "   lying: 0.0\n",
      "   running: 0.0\n",
      "   sitting: 0.0\n",
      "   standing: 0.0\n",
      "   walking: 0.0\n",
      "\n",
      "Precision:\n",
      "   climbing_down: 0.6901408450704225\n",
      "   climbing_up: 0.7528795811518325\n",
      "   jumping: 0.0\n",
      "   lying: 0.0\n",
      "   running: 0.0\n",
      "   sitting: 0.0\n",
      "   standing: 0.0\n",
      "   walking: 0.0\n",
      "\n",
      "Recall:\n",
      "   climbing_down: 0.6749311294765841\n",
      "   climbing_up: 0.7657082002129926\n",
      "   jumping: 0.0\n",
      "   lying: 0.0\n",
      "   running: 0.0\n",
      "   sitting: 0.0\n",
      "   standing: 0.0\n",
      "   walking: 0.0\n",
      "\n",
      "F1:\n",
      "   climbing_down: 0.6824512534818942\n",
      "   climbing_up: 0.7592397043294616\n",
      "   jumping: 0.0\n",
      "   lying: 0.0\n",
      "   running: 0.0\n",
      "   sitting: 0.0\n",
      "   standing: 0.0\n",
      "   walking: 0.0\n",
      "\n",
      "GENERALIZATION GAP ANALYSIS: \n",
      "\n",
      "Train-Val-Accuracy Difference: 0.022449722590564658\n",
      "Train-Val-Precision Difference: 0.020521368789742533\n",
      "Train-Val-Recall Difference: 0.01956837098374664\n",
      "Train-Val-F1 Difference: 0.01904321328532077\n",
      "\n",
      " VALIDATING FOR SUBJECT 2 OF 3\n",
      "(115600, 5) (49976, 5)\n",
      "(3301, 50, 4) (3301,)\n",
      "(1427, 50, 4) (1427,)\n",
      "+----------------------------+------------+\n",
      "|          Modules           | Parameters |\n",
      "+----------------------------+------------+\n",
      "| conv_blocks.0.conv1.weight |    704     |\n",
      "|  conv_blocks.0.conv1.bias  |     64     |\n",
      "| conv_blocks.0.conv2.weight |   45056    |\n",
      "|  conv_blocks.0.conv2.bias  |     64     |\n",
      "| conv_blocks.1.conv1.weight |   45056    |\n",
      "|  conv_blocks.1.conv1.bias  |     64     |\n",
      "| conv_blocks.1.conv2.weight |   45056    |\n",
      "|  conv_blocks.1.conv2.bias  |     64     |\n",
      "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
      "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
      "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
      "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
      "|         fc.weight          |    1024    |\n",
      "|          fc.bias           |     8      |\n",
      "+----------------------------+------------+\n",
      "Total Params: 302024\n",
      "EPOCH: 1/10 \n",
      "Train Loss: 1.3247 Train Acc (M): 0.0789 Train Prc (M): 0.1269 Train Rcl (M): 0.1151 Train F1 (M): 0.1199 Train Acc (W): 0.3153 Train Prc (W): 0.5109 Train Rcl (W): 0.4574 Train F1 (W): 0.4795 \n",
      "Valid Loss: 0.7588 Valid Acc (M): 0.0630 Valid Prc (M): 0.0630 Valid Rcl (M): 0.1250 Valid F1 (M): 0.0838 Valid Acc (W): 0.2539 Valid Prc (W): 0.2539 Valid Rcl (W): 0.5039 Valid F1 (W): 0.3376\n",
      "Performance improved... (0.0->0.33504193849021435)\n",
      "EPOCH: 2/10 \n",
      "Train Loss: 0.8205 Train Acc (M): 0.0875 Train Prc (M): 0.1293 Train Rcl (M): 0.1292 Train F1 (M): 0.1290 Train Acc (W): 0.3542 Train Prc (W): 0.5201 Train Rcl (W): 0.5232 Train F1 (W): 0.5208 \n",
      "Valid Loss: 0.7100 Valid Acc (M): 0.0630 Valid Prc (M): 0.0630 Valid Rcl (M): 0.1250 Valid F1 (M): 0.0838 Valid Acc (W): 0.2539 Valid Prc (W): 0.2539 Valid Rcl (W): 0.5039 Valid F1 (W): 0.3376\n",
      "EPOCH: 3/10 \n",
      "Train Loss: 0.7795 Train Acc (M): 0.0871 Train Prc (M): 0.1289 Train Rcl (M): 0.1288 Train F1 (M): 0.1285 Train Acc (W): 0.3533 Train Prc (W): 0.5187 Train Rcl (W): 0.5229 Train F1 (W): 0.5192 \n",
      "Valid Loss: 0.6944 Valid Acc (M): 0.0630 Valid Prc (M): 0.0630 Valid Rcl (M): 0.1250 Valid F1 (M): 0.0838 Valid Acc (W): 0.2539 Valid Prc (W): 0.2539 Valid Rcl (W): 0.5039 Valid F1 (W): 0.3376\n",
      "EPOCH: 4/10 \n",
      "Train Loss: 0.7590 Train Acc (M): 0.0886 Train Prc (M): 0.1310 Train Rcl (M): 0.1306 Train F1 (M): 0.1296 Train Acc (W): 0.3605 Train Prc (W): 0.5268 Train Rcl (W): 0.5332 Train F1 (W): 0.5252 \n",
      "Valid Loss: 0.7152 Valid Acc (M): 0.0689 Valid Prc (M): 0.1544 Valid Rcl (M): 0.1291 Valid F1 (M): 0.0956 Valid Acc (W): 0.2740 Valid Prc (W): 0.6186 Valid Rcl (W): 0.5130 Valid F1 (W): 0.3803\n",
      "Performance improved... (0.33504193849021435->0.38245994845556613)\n",
      "EPOCH: 5/10 \n",
      "Train Loss: 0.7525 Train Acc (M): 0.0932 Train Prc (M): 0.1355 Train Rcl (M): 0.1354 Train F1 (M): 0.1354 Train Acc (W): 0.3761 Train Prc (W): 0.5447 Train Rcl (W): 0.5462 Train F1 (W): 0.5452 \n",
      "Valid Loss: 0.6826 Valid Acc (M): 0.1087 Valid Prc (M): 0.1686 Valid Rcl (M): 0.1568 Valid F1 (M): 0.1497 Valid Acc (W): 0.4342 Valid Prc (W): 0.6751 Valid Rcl (W): 0.6251 Valid F1 (W): 0.5979\n",
      "Performance improved... (0.38245994845556613->0.5986880595971453)\n",
      "EPOCH: 6/10 \n",
      "Train Loss: 0.7225 Train Acc (M): 0.1002 Train Prc (M): 0.1431 Train Rcl (M): 0.1427 Train F1 (M): 0.1426 Train Acc (W): 0.4051 Train Prc (W): 0.5745 Train Rcl (W): 0.5771 Train F1 (W): 0.5746 \n",
      "Valid Loss: 0.6579 Valid Acc (M): 0.1261 Valid Prc (M): 0.1677 Valid Rcl (M): 0.1676 Valid F1 (M): 0.1676 Valid Acc (W): 0.5044 Valid Prc (W): 0.6707 Valid Rcl (W): 0.6706 Valid F1 (W): 0.6705\n",
      "Performance improved... (0.5986880595971453->0.6704821929007433)\n",
      "EPOCH: 7/10 \n",
      "Train Loss: 0.7004 Train Acc (M): 0.1021 Train Prc (M): 0.1457 Train Rcl (M): 0.1446 Train F1 (M): 0.1441 Train Acc (W): 0.4138 Train Prc (W): 0.5844 Train Rcl (W): 0.5877 Train F1 (W): 0.5821 \n",
      "Valid Loss: 0.6976 Valid Acc (M): 0.0754 Valid Prc (M): 0.1466 Valid Rcl (M): 0.1318 Valid F1 (M): 0.1071 Valid Acc (W): 0.3000 Valid Prc (W): 0.5868 Valid Rcl (W): 0.5242 Valid F1 (W): 0.4266\n",
      "EPOCH: 8/10 \n",
      "Train Loss: 0.6362 Train Acc (M): 0.1218 Train Prc (M): 0.1640 Train Rcl (M): 0.1633 Train F1 (M): 0.1635 Train Acc (W): 0.4906 Train Prc (W): 0.6574 Train Rcl (W): 0.6586 Train F1 (W): 0.6571 \n",
      "Valid Loss: 0.6497 Valid Acc (M): 0.0976 Valid Prc (M): 0.1497 Valid Rcl (M): 0.1446 Valid F1 (M): 0.1387 Valid Acc (W): 0.3896 Valid Prc (W): 0.5990 Valid Rcl (W): 0.5767 Valid F1 (W): 0.5540\n",
      "EPOCH: 9/10 \n",
      "Train Loss: 0.5922 Train Acc (M): 0.1383 Train Prc (M): 0.1796 Train Rcl (M): 0.1775 Train F1 (M): 0.1777 Train Acc (W): 0.5572 Train Prc (W): 0.7179 Train Rcl (W): 0.7171 Train F1 (W): 0.7143 \n",
      "Valid Loss: 0.7770 Valid Acc (M): 0.0781 Valid Prc (M): 0.1437 Valid Rcl (M): 0.1327 Valid F1 (M): 0.1119 Valid Acc (W): 0.3111 Valid Prc (W): 0.5754 Valid Rcl (W): 0.5277 Valid F1 (W): 0.4461\n",
      "EPOCH: 10/10 \n",
      "Train Loss: 0.5572 Train Acc (M): 0.1464 Train Prc (M): 0.1862 Train Rcl (M): 0.1841 Train F1 (M): 0.1844 Train Acc (W): 0.5894 Train Prc (W): 0.7439 Train Rcl (W): 0.7428 Train F1 (W): 0.7406 \n",
      "Valid Loss: 0.7205 Valid Acc (M): 0.0954 Valid Prc (M): 0.1532 Valid Rcl (M): 0.1445 Valid F1 (M): 0.1355 Valid Acc (W): 0.3808 Valid Prc (W): 0.6134 Valid Rcl (W): 0.5760 Valid F1 (W): 0.5408\n",
      "\n",
      "VALIDATION RESULTS FOR SUBJECT 2: \n",
      "\n",
      "Avg. Accuracy: 0.3817533349895547\n",
      "Avg. Precision: 0.6128417578304439\n",
      "Avg. Recall: 0.578174724782537\n",
      "Avg. F1: 0.5418099392377466\n",
      "\n",
      "VALIDATION RESULTS (PER CLASS): \n",
      "\n",
      "Accuracy:\n",
      "   climbing_down: 0.500412881915772\n",
      "   climbing_up: 0.2630937880633374\n",
      "   jumping: 0.0\n",
      "   lying: 0.0\n",
      "   running: 0.0\n",
      "   sitting: 0.0\n",
      "   standing: 0.0\n",
      "   walking: 0.0\n",
      "\n",
      "Precision:\n",
      "   climbing_down: 0.5464382326420198\n",
      "   climbing_up: 0.6792452830188679\n",
      "   jumping: 0.0\n",
      "   lying: 0.0\n",
      "   running: 0.0\n",
      "   sitting: 0.0\n",
      "   standing: 0.0\n",
      "   walking: 0.0\n",
      "\n",
      "Recall:\n",
      "   climbing_down: 0.8559322033898306\n",
      "   climbing_up: 0.3004172461752434\n",
      "   jumping: 0.0\n",
      "   lying: 0.0\n",
      "   running: 0.0\n",
      "   sitting: 0.0\n",
      "   standing: 0.0\n",
      "   walking: 0.0\n",
      "\n",
      "F1:\n",
      "   climbing_down: 0.667033571821684\n",
      "   climbing_up: 0.4165863066538091\n",
      "   jumping: 0.0\n",
      "   lying: 0.0\n",
      "   running: 0.0\n",
      "   sitting: 0.0\n",
      "   standing: 0.0\n",
      "   walking: 0.0\n",
      "\n",
      "GENERALIZATION GAP ANALYSIS: \n",
      "\n",
      "Train-Val-Accuracy Difference: 0.20391048135556594\n",
      "Train-Val-Precision Difference: 0.13176914132335038\n",
      "Train-Val-Recall Difference: 0.1580912242293947\n",
      "Train-Val-F1 Difference: 0.19581116604854565\n",
      "\n",
      " VALIDATING FOR SUBJECT 3 OF 3\n",
      "(108282, 5) (57294, 5)\n",
      "(3092, 50, 4) (3092,)\n",
      "(1636, 50, 4) (1636,)\n",
      "+----------------------------+------------+\n",
      "|          Modules           | Parameters |\n",
      "+----------------------------+------------+\n",
      "| conv_blocks.0.conv1.weight |    704     |\n",
      "|  conv_blocks.0.conv1.bias  |     64     |\n",
      "| conv_blocks.0.conv2.weight |   45056    |\n",
      "|  conv_blocks.0.conv2.bias  |     64     |\n",
      "| conv_blocks.1.conv1.weight |   45056    |\n",
      "|  conv_blocks.1.conv1.bias  |     64     |\n",
      "| conv_blocks.1.conv2.weight |   45056    |\n",
      "|  conv_blocks.1.conv2.bias  |     64     |\n",
      "| lstm_layers.0.weight_ih_l0 |   98304    |\n",
      "| lstm_layers.0.weight_hh_l0 |   65536    |\n",
      "|  lstm_layers.0.bias_ih_l0  |    512     |\n",
      "|  lstm_layers.0.bias_hh_l0  |    512     |\n",
      "|         fc.weight          |    1024    |\n",
      "|          fc.bias           |     8      |\n",
      "+----------------------------+------------+\n",
      "Total Params: 302024\n",
      "EPOCH: 1/10 \n",
      "Train Loss: 1.2658 Train Acc (M): 0.0784 Train Prc (M): 0.1261 Train Rcl (M): 0.1185 Train F1 (M): 0.1158 Train Acc (W): 0.3230 Train Prc (W): 0.5067 Train Rcl (W): 0.4913 Train F1 (W): 0.4739 \n",
      "Valid Loss: 0.7883 Valid Acc (M): 0.0645 Valid Prc (M): 0.0645 Valid Rcl (M): 0.1250 Valid F1 (M): 0.0851 Valid Acc (W): 0.2661 Valid Prc (W): 0.2661 Valid Rcl (W): 0.5159 Valid F1 (W): 0.3511\n",
      "Performance improved... (0.0->0.34032258064516124)\n",
      "EPOCH: 2/10 \n",
      "Train Loss: 0.8113 Train Acc (M): 0.0832 Train Prc (M): 0.1245 Train Rcl (M): 0.1245 Train F1 (M): 0.1241 Train Acc (W): 0.3369 Train Prc (W): 0.5008 Train Rcl (W): 0.5049 Train F1 (W): 0.5012 \n",
      "Valid Loss: 0.7374 Valid Acc (M): 0.0645 Valid Prc (M): 0.0645 Valid Rcl (M): 0.1250 Valid F1 (M): 0.0851 Valid Acc (W): 0.2661 Valid Prc (W): 0.2661 Valid Rcl (W): 0.5159 Valid F1 (W): 0.3511\n",
      "EPOCH: 3/10 \n",
      "Train Loss: 0.7581 Train Acc (M): 0.0858 Train Prc (M): 0.1277 Train Rcl (M): 0.1276 Train F1 (M): 0.1269 Train Acc (W): 0.3480 Train Prc (W): 0.5132 Train Rcl (W): 0.5181 Train F1 (W): 0.5129 \n",
      "Valid Loss: 0.7341 Valid Acc (M): 0.0645 Valid Prc (M): 0.0645 Valid Rcl (M): 0.1250 Valid F1 (M): 0.0851 Valid Acc (W): 0.2661 Valid Prc (W): 0.2661 Valid Rcl (W): 0.5159 Valid F1 (W): 0.3511\n",
      "EPOCH: 4/10 \n",
      "Train Loss: 0.7468 Train Acc (M): 0.0860 Train Prc (M): 0.1277 Train Rcl (M): 0.1276 Train F1 (M): 0.1273 Train Acc (W): 0.3479 Train Prc (W): 0.5133 Train Rcl (W): 0.5168 Train F1 (W): 0.5137 \n",
      "Valid Loss: 0.7422 Valid Acc (M): 0.0702 Valid Prc (M): 0.1208 Valid Rcl (M): 0.1229 Valid F1 (M): 0.1034 Valid Acc (W): 0.2756 Valid Prc (W): 0.4835 Valid Rcl (W): 0.4804 Valid F1 (W): 0.4074\n",
      "Performance improved... (0.34032258064516124->0.4136922630652266)\n",
      "EPOCH: 5/10 \n",
      "Train Loss: 0.7095 Train Acc (M): 0.0981 Train Prc (M): 0.1413 Train Rcl (M): 0.1406 Train F1 (M): 0.1401 Train Acc (W): 0.3968 Train Prc (W): 0.5669 Train Rcl (W): 0.5702 Train F1 (W): 0.5653 \n",
      "Valid Loss: 0.8177 Valid Acc (M): 0.0613 Valid Prc (M): 0.1356 Valid Rcl (M): 0.1253 Valid F1 (M): 0.0832 Valid Acc (W): 0.2377 Valid Prc (W): 0.5441 Valid Rcl (W): 0.4853 Valid F1 (W): 0.3228\n",
      "EPOCH: 6/10 \n",
      "Train Loss: 0.6700 Train Acc (M): 0.1124 Train Prc (M): 0.1560 Train Rcl (M): 0.1547 Train F1 (M): 0.1545 Train Acc (W): 0.4538 Train Prc (W): 0.6248 Train Rcl (W): 0.6261 Train F1 (W): 0.6221 \n",
      "Valid Loss: 0.8756 Valid Acc (M): 0.0605 Valid Prc (M): 0.1021 Valid Rcl (M): 0.1248 Valid F1 (M): 0.0817 Valid Acc (W): 0.2345 Valid Prc (W): 0.4062 Valid Rcl (W): 0.4835 Valid F1 (W): 0.3166\n",
      "EPOCH: 7/10 \n",
      "Train Loss: 0.6204 Train Acc (M): 0.1240 Train Prc (M): 0.1665 Train Rcl (M): 0.1654 Train F1 (M): 0.1655 Train Acc (W): 0.4996 Train Prc (W): 0.6665 Train Rcl (W): 0.6672 Train F1 (W): 0.6649 \n",
      "Valid Loss: 0.9351 Valid Acc (M): 0.0607 Valid Prc (M): 0.1230 Valid Rcl (M): 0.1250 Valid F1 (M): 0.0821 Valid Acc (W): 0.2353 Valid Prc (W): 0.4923 Valid Rcl (W): 0.4841 Valid F1 (W): 0.3180\n",
      "EPOCH: 8/10 \n",
      "Train Loss: 0.5717 Train Acc (M): 0.1366 Train Prc (M): 0.1773 Train Rcl (M): 0.1762 Train F1 (M): 0.1764 Train Acc (W): 0.5492 Train Prc (W): 0.7093 Train Rcl (W): 0.7096 Train F1 (W): 0.7082 \n",
      "Valid Loss: 0.9201 Valid Acc (M): 0.0607 Valid Prc (M): 0.1230 Valid Rcl (M): 0.1250 Valid F1 (M): 0.0821 Valid Acc (W): 0.2353 Valid Prc (W): 0.4923 Valid Rcl (W): 0.4841 Valid F1 (W): 0.3180\n",
      "EPOCH: 9/10 \n",
      "Train Loss: 0.5372 Train Acc (M): 0.1463 Train Prc (M): 0.1852 Train Rcl (M): 0.1842 Train F1 (M): 0.1844 Train Acc (W): 0.5879 Train Prc (W): 0.7409 Train Rcl (W): 0.7409 Train F1 (W): 0.7398 \n",
      "Valid Loss: 0.9498 Valid Acc (M): 0.0608 Valid Prc (M): 0.1230 Valid Rcl (M): 0.1250 Valid F1 (M): 0.0823 Valid Acc (W): 0.2357 Valid Prc (W): 0.4923 Valid Rcl (W): 0.4841 Valid F1 (W): 0.3191\n",
      "EPOCH: 10/10 \n",
      "Train Loss: 0.4959 Train Acc (M): 0.1590 Train Prc (M): 0.1957 Train Rcl (M): 0.1939 Train F1 (M): 0.1942 Train Acc (W): 0.6388 Train Prc (W): 0.7818 Train Rcl (W): 0.7804 Train F1 (W): 0.7790 \n",
      "Valid Loss: 1.0666 Valid Acc (M): 0.0616 Valid Prc (M): 0.1482 Valid Rcl (M): 0.1256 Valid F1 (M): 0.0836 Valid Acc (W): 0.2387 Valid Prc (W): 0.5960 Valid Rcl (W): 0.4866 Valid F1 (W): 0.3244\n",
      "\n",
      "VALIDATION RESULTS FOR SUBJECT 3: \n",
      "\n",
      "Avg. Accuracy: 0.24630534374381685\n",
      "Avg. Precision: 0.592619926199262\n",
      "Avg. Recall: 0.5022529800373402\n",
      "Avg. F1: 0.33449945084001137\n",
      "\n",
      "VALIDATION RESULTS (PER CLASS): \n",
      "\n",
      "Accuracy:\n",
      "   climbing_down: 0.4843462246777164\n",
      "   climbing_up: 0.008264462809917356\n",
      "   jumping: 0.0\n",
      "   lying: 0.0\n",
      "   running: 0.0\n",
      "   sitting: 0.0\n",
      "   standing: 0.0\n",
      "   walking: 0.0\n",
      "\n",
      "Precision:\n",
      "   climbing_down: 0.48523985239852396\n",
      "   climbing_up: 0.7\n",
      "   jumping: 0.0\n",
      "   lying: 0.0\n",
      "   running: 0.0\n",
      "   sitting: 0.0\n",
      "   standing: 0.0\n",
      "   walking: 0.0\n",
      "\n",
      "Recall:\n",
      "   climbing_down: 0.9962121212121212\n",
      "   climbing_up: 0.008293838862559242\n",
      "   jumping: 0.0\n",
      "   lying: 0.0\n",
      "   running: 0.0\n",
      "   sitting: 0.0\n",
      "   standing: 0.0\n",
      "   walking: 0.0\n",
      "\n",
      "F1:\n",
      "   climbing_down: 0.6526054590570719\n",
      "   climbing_up: 0.01639344262295082\n",
      "   jumping: 0.0\n",
      "   lying: 0.0\n",
      "   running: 0.0\n",
      "   sitting: 0.0\n",
      "   standing: 0.0\n",
      "   walking: 0.0\n",
      "\n",
      "GENERALIZATION GAP ANALYSIS: \n",
      "\n",
      "Train-Val-Accuracy Difference: 0.38978480723169406\n",
      "Train-Val-Precision Difference: 0.19020382432274396\n",
      "Train-Val-Recall Difference: 0.27319735332795847\n",
      "Train-Val-F1 Difference: 0.4424433148504901\n"
     ]
    }
   ],
   "source": [
    "# needed for saving results\n",
    "log_date = time.strftime('%Y%m%d')\n",
    "log_timestamp = time.strftime('%H%M%S')\n",
    "\n",
    "# in order to get reproducible results, we need to seed torch and other random parts of our implementation\n",
    "seed_torch(config['seed'])\n",
    "unique_sub = np.unique(train_valid_data[:,0])\n",
    "\n",
    "# iterate over all subjects\n",
    "for i, sbj in enumerate(unique_sub):\n",
    "    print('\\n VALIDATING FOR SUBJECT {0} OF {1}'.format(int(sbj) + 1, int(np.max(train_valid_data[:, 0])) + 1))\n",
    "    \n",
    "    # define the train data to be everything, but the data of the current subject\n",
    "    train_data = train_valid_data[train_valid_data[:,0] != sbj]\n",
    "    # define the validation data to be the data of the current subject\n",
    "    valid_data = train_valid_data[train_valid_data[:,0] == sbj]\n",
    "    \n",
    "    print(train_data.shape, valid_data.shape)\n",
    "    \n",
    "    # apply the sliding window on top of both the train and validation data; use the \"apply_sliding_window\" function\n",
    "    # found in data_processing.sliding_window\n",
    "    X_train, y_train = apply_sliding_window(train_data[:, :-1], train_data[:, -1], sliding_window_size=config['sw_length'], unit=config['sw_unit'], sampling_rate=config['sampling_rate'], sliding_window_overlap=config['sw_overlap'])\n",
    "\n",
    "    print(X_train.shape, y_train.shape)\n",
    "\n",
    "    X_valid, y_valid = apply_sliding_window(valid_data[:, :-1], valid_data[:, -1], sliding_window_size=config['sw_length'], unit=config['sw_unit'], sampling_rate=config['sampling_rate'], sliding_window_overlap=config['sw_overlap'])\n",
    "\n",
    "    print(X_valid.shape, y_valid.shape)\n",
    "\n",
    "    # (optional) omit the first feature column (subject_identifier) from the train and validation dataset\n",
    "    # you can do it if you want to as it is not a useful feature\n",
    "    X_train, X_valid = X_train[:, :, 1:], X_valid[:, :, 1:]\n",
    "    \n",
    "    # within the config file, set the parameters 'window_size' and 'nb_channels' accordingly\n",
    "    # window_size = size of the sliding window in units\n",
    "    # nb_channels = number of feature channels\n",
    "    config['window_size'] = X_train.shape[1]\n",
    "    config['nb_channels'] = X_train.shape[2]\n",
    "    \n",
    "    # define the network to be a DeepConvLSTM object; can be imported from model.DeepConvLSTM\n",
    "    # pass it the config object\n",
    "    net = DeepConvLSTM(config=config)\n",
    "\n",
    "    # defines the loss and optimizer\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    opt = torch.optim.Adam(net.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "\n",
    "    # convert the features of the train and validation to float32 and labels to uint8 for GPU compatibility \n",
    "    X_train, y_train = X_train.astype(np.float32), y_train.astype(np.uint8)\n",
    "    X_valid, y_valid = X_valid.astype(np.float32), y_valid.astype(np.uint8)\n",
    "\n",
    "    cross_participant_net,_, val_output, train_output = train(X_train, y_train, X_valid, y_valid, network=net, optimizer=opt, loss=loss, config=config, log_date=log_date, log_timestamp=log_timestamp)\n",
    "    \n",
    "    # the next bit prints out the average results per subject if you did everything correctly\n",
    "    cls = np.array(range(config['nb_classes']))\n",
    "    \n",
    "    print('\\nVALIDATION RESULTS FOR SUBJECT {0}: '.format(int(sbj) + 1))\n",
    "    print(\"\\nAvg. Accuracy: {0}\".format(jaccard_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
    "    print(\"Avg. Precision: {0}\".format(precision_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
    "    print(\"Avg. Recall: {0}\".format(recall_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
    "    print(\"Avg. F1: {0}\".format(f1_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
    "\n",
    "    print(\"\\nVALIDATION RESULTS (PER CLASS): \")\n",
    "    print(\"\\nAccuracy:\")\n",
    "    for i, rslt in enumerate(jaccard_score(val_output[:, 1], val_output[:, 0], average=None, labels=cls)):\n",
    "        print(\"   {0}: {1}\".format(class_names[i], rslt))\n",
    "    print(\"\\nPrecision:\")\n",
    "    for i, rslt in enumerate(precision_score(val_output[:, 1], val_output[:, 0], average=None, labels=cls)):\n",
    "        print(\"   {0}: {1}\".format(class_names[i], rslt))\n",
    "    print(\"\\nRecall:\")\n",
    "    for i, rslt in enumerate(recall_score(val_output[:, 1], val_output[:, 0], average=None, labels=cls)):\n",
    "        print(\"   {0}: {1}\".format(class_names[i], rslt))\n",
    "    print(\"\\nF1:\")\n",
    "    for i, rslt in enumerate(f1_score(val_output[:, 1], val_output[:, 0], average=None, labels=cls)):\n",
    "        print(\"   {0}: {1}\".format(class_names[i], rslt))\n",
    "\n",
    "    print(\"\\nGENERALIZATION GAP ANALYSIS: \")\n",
    "    print(\"\\nTrain-Val-Accuracy Difference: {0}\".format(jaccard_score(train_output[:, 1], train_output[:, 0], average='macro') -\n",
    "                                                      jaccard_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
    "    print(\"Train-Val-Precision Difference: {0}\".format(precision_score(train_output[:, 1], train_output[:, 0], average='macro') -\n",
    "                                                       precision_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
    "    print(\"Train-Val-Recall Difference: {0}\".format(recall_score(train_output[:, 1], train_output[:, 0], average='macro') -\n",
    "                                                    recall_score(val_output[:, 1], val_output[:, 0], average='macro')))\n",
    "    print(\"Train-Val-F1 Difference: {0}\".format(f1_score(train_output[:, 1], train_output[:, 0], average='macro') -\n",
    "                                                f1_score(val_output[:, 1], val_output[:, 0], average='macro')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jTFNUytOl9BM"
   },
   "source": [
    "## 5.4 Testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "RXvP175Tl9BM"
   },
   "source": [
    "Now, after having implemented each of the validation techniques we want to get an unbiased view of how our trained algorithm perfoms on unseen data. To do so we use the testing set which we split off the original dataset within the first step of this notebook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "r4cmr2Tll9BM"
   },
   "source": [
    "### Task 5: Testing your trained networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "mHRkzAaul9BM"
   },
   "source": [
    "1. Apply the `apply_sliding_window()` function on top of the `test` data. (`lines 6-8`)\n",
    "2. (*Optional*) Omit the first feature column (subject_identifier) from the test dataset. (`lines 11-13`)\n",
    "3. Convert the feature columns of the test dataset to `float32` and label column to `uint8` for GPU compatibility. Use the [built-in function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html) of a pandas dataframe called `astype()`. (`lines 16-17`)\n",
    "4. Using the `predict()` function of the DL-ARC GitHub to obtain results on the `test` data using each of the trained networks as input. The function is already imported for you. (`lines 19-28`)\n",
    "5. Which model does perform the best and why? Was this expected? Can you make out a reason why that is? \n",
    "6. What would you change about the pipeline we just created if your goal was to get the best predictions possible? Hint: think about the amount of data which actually trained your model in the end!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "L9s6kwjul9BM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 50, 4) (404,)\n",
      "COMPILED TEST RESULTS: \n",
      "\n",
      "Test results (train-valid-split): \n",
      "\n",
      "TEST RESULTS: \n",
      "Avg. Accuracy: 0.0\n",
      "Avg. Precision: 0.0\n",
      "Avg. Recall: 0.0\n",
      "Avg. F1: 0.0\n",
      "\n",
      "TEST RESULTS (PER CLASS): \n",
      "Accuracy: [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Precision: [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Recall: [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "F1: [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Test results (k-fold): \n",
      "\n",
      "TEST RESULTS: \n",
      "Avg. Accuracy: 0.0\n",
      "Avg. Precision: 0.0\n",
      "Avg. Recall: 0.0\n",
      "Avg. F1: 0.0\n",
      "\n",
      "TEST RESULTS (PER CLASS): \n",
      "Accuracy: [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Precision: [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Recall: [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "F1: [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Test results (cross-participant): \n",
      "\n",
      "TEST RESULTS: \n",
      "Avg. Accuracy: 0.0\n",
      "Avg. Precision: 0.0\n",
      "Avg. Recall: 0.0\n",
      "Avg. F1: 0.0\n",
      "\n",
      "TEST RESULTS (PER CLASS): \n",
      "Accuracy: [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Precision: [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Recall: [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "F1: [0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1]),\n",
       " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.train import predict\n",
    "\n",
    "# in order to get reproducible results, we need to seed torch and other random parts of our implementation\n",
    "seed_torch(config['seed'])\n",
    "\n",
    "# apply the sliding window on top of both the test data; use the \"apply_sliding_window\" function\n",
    "# found in data_processing.sliding_window\n",
    "X_test, y_test = apply_sliding_window(test_data[:, :-1], test_data[:, -1], sliding_window_size=config['sw_length'], unit=config['sw_unit'], sampling_rate=config['sampling_rate'], sliding_window_overlap=config['sw_overlap'])\n",
    "\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "# (optional) omit the first feature column (subject_identifier) from the test dataset\n",
    "# you need to do it if you did so during training and validation!\n",
    "X_test = X_test[:, :, 1:]\n",
    "\n",
    "# convert the features of test to float32 and labels to uint8 for GPU compatibility \n",
    "X_test, y_test = X_test.astype(np.float32), y_test.astype(np.uint8)\n",
    "\n",
    "# the next lines will print out the test results for each of the trained networks\n",
    "print('COMPILED TEST RESULTS: ')\n",
    "print('\\nTest results (train-valid-split): ')\n",
    "predict(test_features= X_test, test_labels= y_test, network= train_valid_net, config=config, log_date=log_date, log_timestamp=log_timestamp)\n",
    "\n",
    "print('\\nTest results (k-fold): ')\n",
    "predict(test_features= X_test, test_labels= y_test, network= kfold_net, config=config, log_date=log_date, log_timestamp=log_timestamp)\n",
    "\n",
    "print('\\nTest results (cross-participant): ')\n",
    "predict(test_features= X_test, test_labels= y_test, network= cross_participant_net, config=config, log_date=log_date, log_timestamp=log_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "validation_and_testing.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
